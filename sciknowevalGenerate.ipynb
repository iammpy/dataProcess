{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e9b805",
   "metadata": {},
   "source": [
    "### 初始化全局变量，导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "610ff416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10415"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from model import call_huoshan,call_openai\n",
    "import pandas as pd\n",
    "import json \n",
    "if \"__file__\" in globals():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_tag=\"openended_filling\"\n",
    "sciKnowEval_path = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "if sciKnowEval_path.endswith(\".jsonl\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= [json.loads(line) for line in f if line.strip()]\n",
    "elif sciKnowEval_path.endswith(\".json\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= json.load(f)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file format: {sciKnowEval_path}\")\n",
    "len(sciKnowEval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4bcbd407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "experiment-protocol-3205\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for row in sciKnowEval_data:\n",
    "    id= row[\"id\"]\n",
    "    if id==\"50aab6cbc8cdba530aa43d36a26a8bb7\":\n",
    "        print(row[\"metadata\"][\"details\"][\"source\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7451635",
   "metadata": {},
   "outputs": [],
   "source": [
    "sciKnowEval_data_dict = {row[\"id\"]: row for row in sciKnowEval_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61317204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_pure.json\"), \"r\") as f:\n",
    "    sciKnowEval_score = json.load(f)\n",
    "for row in sciKnowEval_score:\n",
    "    id = row[\"id\"]\n",
    "    if id in sciKnowEval_data_dict:\n",
    "        source = sciKnowEval_data_dict[id][\"metadata\"][\"details\"][\"source\"]\n",
    "        row[\"source\"] = source\n",
    "    else:\n",
    "        print(f\"ID {id} not found in sciKnowEval_data_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89811430",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_pure.json\"), \"w\") as f:\n",
    "    json.dump(sciKnowEval_score, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff81d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sciKnowEval_path, \"w\") as f:\n",
    "    json.dump(sciKnowEval_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd28430",
   "metadata": {},
   "source": [
    "#### sciKnowEval的验证器，openEnded问题使用模型验证，其余使用规则直接比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from threading import Lock\n",
    "from mpy_utils import predict_bandgap_for_structure\n",
    "import json\n",
    "import json_repair\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "MPLock = Lock()\n",
    "def sciKnowEval_rule_verifier(answer_content: str,groundtruth: str, question: str, row=None):\n",
    "    \n",
    "    pattern = r\"\\\\boxed{\\\\text{(.*?)}\"\n",
    "    match = re.search(pattern, answer_content)\n",
    "\n",
    "    # 如果匹配成功，提取捕获的内容\n",
    "    if match:\n",
    "        extracted_answer = match.group(1)\n",
    "      \n",
    "    else:\n",
    "        return False\n",
    "   \n",
    "    if groundtruth.lower() == extracted_answer.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def sciKnowEval_model_verifier(question: str, groundtruth: str, model_content: str) -> bool:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI verifier. Your task is to determine if the `model_content` is a correct or acceptable response to the `question`, considering the `groundtruth` as the reference for correctness. Output only \"True\" or \"False\".\n",
    "\n",
    "[Context and Inputs Start]\n",
    "Question: {question}\n",
    "Ground Truth: {groundtruth}\n",
    "Model Content: {model_content}\n",
    "[Context and Inputs End]\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Compare the `model_content` with the `groundtruth` in the context of the `question`.\n",
    "\n",
    "\"The model_content is \"True\" if it proposes a scientifically sound and well-reasoned modification to the starting material, correctly applying one of the specified modification types from the question, and the proposed new material is a logical outcome of this modification. The rationale should clearly explain how this modification is expected to lead towards the target property. The groundtruth serves as a reference for a potentially valid outcome, but a well-argued alternative solution that also meets the question's constraints and scientific principles is also considered \"True\".\"\n",
    "\n",
    "The model_content is \"False\" if it:\n",
    "Fails to apply a valid modification type as specified in the question to the correct starting material.\n",
    "Contains critical scientific flaws in its reasoning or proposed modification.\n",
    "The proposed new material is not a logical or direct result of the described modification process.\n",
    "Fundamentally misunderstands the scientific goal or constraints of the question.\n",
    "\n",
    "Strictly output \"True\" or \"False\". Do not add any explanation or other characters.\n",
    "\n",
    "Your output is:\n",
    "\"\"\"\n",
    "\n",
    "    _,llm_response=call_openai(prompt)\n",
    "    if llm_response.strip().lower() == \"true\":\n",
    "        return True\n",
    "    elif llm_response.strip().lower() == \"false\":\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"Unexpected LLM response: {llm_response}\")\n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ecd91",
   "metadata": {},
   "source": [
    "#### 处理sciKnowEval数据：生成generation，调用verifier，整合成符合要求的最终dict格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "Lock = Lock()\n",
    "new_list= []\n",
    "\n",
    "def sciKnowEval_process_row(row):\n",
    "    \n",
    "    # if len(row[\"generations\"]) >=5:\n",
    "    #     return\n",
    "    # task_type = row[\"metadata\"][\"task_type\"]\n",
    "    final_answer = row[\"ground_truth\"][\"final_answer\"]\n",
    "\n",
    "    prompt = row[\"question\"]\n",
    "    domain = row[\"metadata\"][\"domain\"]\n",
    "    subtask = row[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    \n",
    "    # generations:list= row[\"generations\"]\n",
    "    generations = row[\"generations\"] \n",
    "    # try_nums = 0\n",
    "    # while len(generations)<5: # 调用模型的次数，暂定为1\n",
    "        \n",
    "    #     generation={}\n",
    "    #     generation[\"model\"] = \"DeepSeek-R1\"\n",
    "    #     reasoning_content, answer_content = call_huoshan(prompt,\"r1\")\n",
    "    #     answer_content=answer_content.strip()\n",
    "    #     reasoning_content=reasoning_content.strip()\n",
    "\n",
    "    #     generation[\"reasoning_content\"] = reasoning_content\n",
    "    #     generation[\"answer_content\"] = answer_content\n",
    "    #     if len(answer_content) <5:\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {answer_content}|\")\n",
    "    #         try_nums += 1\n",
    "    #         if try_nums > 5:\n",
    "    #             print(f\"Warning: Too many short answer attempts in row {row['id']}. Skipping this row.\")\n",
    "    #             return\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #         continue\n",
    "    #     # Verify the model content\n",
    "    #     evaluation={}\n",
    "    \n",
    "    #     correctness = sciKnowEval_rule_verifier(answer_content,final_answer,prompt )\n",
    "    #     evaluation[\"correctness\"] = correctness\n",
    "    #     evaluation[\"By\"] = \"mengpengyu\"\n",
    "    #     evaluation[\"Method\"] =  \"Rule\"\n",
    "    #     evaluation[\"extra_tags\"] = []\n",
    "    #     generation[\"evaluation\"] = evaluation\n",
    "    #     generations.append(generation)\n",
    "        \n",
    "    # for generation in row[\"generations\"]:\n",
    "    #     if not generation[\"answer_content\"].strip():\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {generation['answer_content']}|\")\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #     else:\n",
    "    #         generations.append(generation)\n",
    "    # row[\"generations\"] = generations\n",
    "    if len(row[\"generations\"]) <5:\n",
    "        # print(f\"Warning: Less than 5 generations in row {row['id']}. nums of generations: {len(row['generations'])}\")\n",
    "        if len(row[\"generations\"]) == 0:\n",
    "            print(f\"Warning: No generations found in row {row['id']}.\")\n",
    "            print(f\"Question: {prompt}\")\n",
    "            return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    with Lock:   \n",
    "        if len(row['generations']) == 0:\n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": 0.0}\n",
    "        else:  \n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": sum(1 for gen in row[\"generations\"] if gen[\"evaluation\"][\"correctness\"]) / len(row[\"generations\"])}\n",
    "        # row[\"generations\"]=generations\n",
    "        # row[\"solve_rate\"] = sum(1 for gen in generations if gen[\"evaluation\"][\"correctness\"]) / len(generations)\n",
    "\n",
    "        new_dict = {}\n",
    "        for key, value in row.items():\n",
    "            if key == \"task_type\":\n",
    "            \n",
    "                new_dict[\"type\"] = value\n",
    "            elif key == \"languages\":\n",
    "                new_dict[\"languages\"] = [\n",
    "                    value\n",
    "                ]\n",
    "            else:\n",
    "                # 其他键值对直接复制过来\n",
    "                new_dict[key] = value\n",
    "        new_list.append(new_dict)\n",
    "    return 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6205b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pdb\n",
    "num=0\n",
    "with ThreadPoolExecutor(max_workers=400) as executor:\n",
    "    counter = 0\n",
    "    futures = {executor.submit(sciKnowEval_process_row, row): index for index, row in enumerate(sciKnowEval_data)}\n",
    "    for future in as_completed(futures):\n",
    "        index = futures[future]\n",
    "        return_num= future.result()\n",
    "        # if return_num ==0:\n",
    "        #     num+=1\n",
    "        #     # print(f\"成功修复了 {num} 个数据。\")\n",
    "        # try:\n",
    "        #     future.result()  # 获取结果，确保异常被捕获\n",
    "        #     counter += 1\n",
    "        #     # if counter % 10 == 0:\n",
    "        #         # print(f\"Processed {counter} rows.\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error processing row {index}: {e}\")\n",
    "        #     traceback.print_exc() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2048441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = \"openended_filling\"\n",
    "# 将结果写入JSONL文件\n",
    "output_file = os.path.join(raw_data_path, f\"SciKnowEval_processed_{data_tag}.jsonl\")\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        for row in sciKnowEval_data:\n",
    "            if len(row[\"generations\"]) ==0:\n",
    "                print(f\"Warning: zero generations in row {row['id']}\")\n",
    "                continue\n",
    "            json_str=json.dumps(row, ensure_ascii=False)\n",
    "            f.write(json_str + \"\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    with open(sciKnowEval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        json.dump(new_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608a199",
   "metadata": {},
   "source": [
    "#### 采集各类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a117f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_path= os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Total number of processed entries: {len(data)}\")\n",
    "\n",
    "sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "new_list=[]\n",
    "## 各个subtask采集5个数据\n",
    "for entry in data:\n",
    "    subtask = entry[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    domain = entry[\"metadata\"][\"domain\"]\n",
    "    task= entry[\"metadata\"][\"details\"][\"task\"]\n",
    "    if sum_dict[domain][task][subtask] < 5:\n",
    "        sum_dict[domain][task][subtask] += 1\n",
    "        new_list.append(entry)\n",
    "print(f\"Total number of entries after filtering: {len(new_list)}\")\n",
    "output_file = os.path.join(raw_data_path, f\"data_sample.json\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_list, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
