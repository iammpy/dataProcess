{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e9b805",
   "metadata": {},
   "source": [
    "### åˆå§‹åŒ–å…¨å±€å˜é‡ï¼Œå¯¼å…¥åŒ…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ff416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10300"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from model import call_huoshan,call_openai\n",
    "import pandas as pd\n",
    "import json \n",
    "if \"__file__\" in globals():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_tag=\"openended_filling\"\n",
    "sciKnowEval_path = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "if sciKnowEval_path.endswith(\".jsonl\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= [json.loads(line) for line in f if line.strip()]\n",
    "elif sciKnowEval_path.endswith(\".json\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= json.load(f)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file format: {sciKnowEval_path}\")\n",
    "len(sciKnowEval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7451635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = []\n",
    "count=0\n",
    "for row in sciKnowEval_data:\n",
    "    task= row[\"task\"]\n",
    "    if task==\"harmful_QA\":\n",
    "        count+=1\n",
    "        continue\n",
    "    new_data.append(row)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61317204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_pure.json\"), \"r\") as f:\n",
    "    sciKnowEval_score = json.load(f)\n",
    "for row in sciKnowEval_score:\n",
    "    id = row[\"id\"]\n",
    "    if id in sciKnowEval_data_dict:\n",
    "        source = sciKnowEval_data_dict[id][\"metadata\"][\"details\"][\"source\"]\n",
    "        row[\"source\"] = source\n",
    "    else:\n",
    "        print(f\"ID {id} not found in sciKnowEval_data_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89811430",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_vote.json\"), \"w\") as f:\n",
    "    json.dump(new_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff81d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sciKnowEval_path, \"w\") as f:\n",
    "    json.dump(sciKnowEval_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd28430",
   "metadata": {},
   "source": [
    "#### sciKnowEvalçš„éªŒè¯å™¨ï¼ŒopenEndedé—®é¢˜ä½¿ç”¨æ¨¡å‹éªŒè¯ï¼Œå…¶ä½™ä½¿ç”¨è§„åˆ™ç›´æ¥æ¯”å¯¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from threading import Lock\n",
    "from mpy_utils import predict_bandgap_for_structure\n",
    "import json\n",
    "import json_repair\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "MPLock = Lock()\n",
    "def sciKnowEval_rule_verifier(answer_content: str,groundtruth: str, question: str, row=None):\n",
    "    \n",
    "    pattern = r\"\\\\boxed{\\\\text{(.*?)}\"\n",
    "    match = re.search(pattern, answer_content)\n",
    "\n",
    "    # å¦‚æœåŒ¹é…æˆåŠŸï¼Œæå–æ•è·çš„å†…å®¹\n",
    "    if match:\n",
    "        extracted_answer = match.group(1)\n",
    "      \n",
    "    else:\n",
    "        return False\n",
    "   \n",
    "    if groundtruth.lower() == extracted_answer.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def sciKnowEval_model_verifier(question: str, groundtruth: str, model_content: str) -> bool:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI verifier. Your task is to determine if the `model_content` is a correct or acceptable response to the `question`, considering the `groundtruth` as the reference for correctness. Output only \"True\" or \"False\".\n",
    "\n",
    "[Context and Inputs Start]\n",
    "Question: {question}\n",
    "Ground Truth: {groundtruth}\n",
    "Model Content: {model_content}\n",
    "[Context and Inputs End]\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Compare the `model_content` with the `groundtruth` in the context of the `question`.\n",
    "\n",
    "\"The model_content is \"True\" if it proposes a scientifically sound and well-reasoned modification to the starting material, correctly applying one of the specified modification types from the question, and the proposed new material is a logical outcome of this modification. The rationale should clearly explain how this modification is expected to lead towards the target property. The groundtruth serves as a reference for a potentially valid outcome, but a well-argued alternative solution that also meets the question's constraints and scientific principles is also considered \"True\".\"\n",
    "\n",
    "The model_content is \"False\" if it:\n",
    "Fails to apply a valid modification type as specified in the question to the correct starting material.\n",
    "Contains critical scientific flaws in its reasoning or proposed modification.\n",
    "The proposed new material is not a logical or direct result of the described modification process.\n",
    "Fundamentally misunderstands the scientific goal or constraints of the question.\n",
    "\n",
    "Strictly output \"True\" or \"False\". Do not add any explanation or other characters.\n",
    "\n",
    "Your output is:\n",
    "\"\"\"\n",
    "\n",
    "    _,llm_response=call_openai(prompt)\n",
    "    if llm_response.strip().lower() == \"true\":\n",
    "        return True\n",
    "    elif llm_response.strip().lower() == \"false\":\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"Unexpected LLM response: {llm_response}\")\n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ecd91",
   "metadata": {},
   "source": [
    "#### å¤„ç†sciKnowEvalæ•°æ®ï¼šç”Ÿæˆgenerationï¼Œè°ƒç”¨verifierï¼Œæ•´åˆæˆç¬¦åˆè¦æ±‚çš„æœ€ç»ˆdictæ ¼å¼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "Lock = Lock()\n",
    "new_list= []\n",
    "\n",
    "def sciKnowEval_process_row(row):\n",
    "    \n",
    "    # if len(row[\"generations\"]) >=5:\n",
    "    #     return\n",
    "    # task_type = row[\"metadata\"][\"task_type\"]\n",
    "    final_answer = row[\"ground_truth\"][\"final_answer\"]\n",
    "\n",
    "    prompt = row[\"question\"]\n",
    "    domain = row[\"metadata\"][\"domain\"]\n",
    "    subtask = row[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    \n",
    "    # generations:list= row[\"generations\"]\n",
    "    generations = row[\"generations\"] \n",
    "    # try_nums = 0\n",
    "    # while len(generations)<5: # è°ƒç”¨æ¨¡å‹çš„æ¬¡æ•°ï¼Œæš‚å®šä¸º1\n",
    "        \n",
    "    #     generation={}\n",
    "    #     generation[\"model\"] = \"DeepSeek-R1\"\n",
    "    #     reasoning_content, answer_content = call_huoshan(prompt,\"r1\")\n",
    "    #     answer_content=answer_content.strip()\n",
    "    #     reasoning_content=reasoning_content.strip()\n",
    "\n",
    "    #     generation[\"reasoning_content\"] = reasoning_content\n",
    "    #     generation[\"answer_content\"] = answer_content\n",
    "    #     if len(answer_content) <5:\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {answer_content}|\")\n",
    "    #         try_nums += 1\n",
    "    #         if try_nums > 5:\n",
    "    #             print(f\"Warning: Too many short answer attempts in row {row['id']}. Skipping this row.\")\n",
    "    #             return\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #         continue\n",
    "    #     # Verify the model content\n",
    "    #     evaluation={}\n",
    "    \n",
    "    #     correctness = sciKnowEval_rule_verifier(answer_content,final_answer,prompt )\n",
    "    #     evaluation[\"correctness\"] = correctness\n",
    "    #     evaluation[\"By\"] = \"mengpengyu\"\n",
    "    #     evaluation[\"Method\"] =  \"Rule\"\n",
    "    #     evaluation[\"extra_tags\"] = []\n",
    "    #     generation[\"evaluation\"] = evaluation\n",
    "    #     generations.append(generation)\n",
    "        \n",
    "    # for generation in row[\"generations\"]:\n",
    "    #     if not generation[\"answer_content\"].strip():\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {generation['answer_content']}|\")\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #     else:\n",
    "    #         generations.append(generation)\n",
    "    # row[\"generations\"] = generations\n",
    "    if len(row[\"generations\"]) <5:\n",
    "        # print(f\"Warning: Less than 5 generations in row {row['id']}. nums of generations: {len(row['generations'])}\")\n",
    "        if len(row[\"generations\"]) == 0:\n",
    "            print(f\"Warning: No generations found in row {row['id']}.\")\n",
    "            print(f\"Question: {prompt}\")\n",
    "            return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    with Lock:   \n",
    "        if len(row['generations']) == 0:\n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": 0.0}\n",
    "        else:  \n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": sum(1 for gen in row[\"generations\"] if gen[\"evaluation\"][\"correctness\"]) / len(row[\"generations\"])}\n",
    "        # row[\"generations\"]=generations\n",
    "        # row[\"solve_rate\"] = sum(1 for gen in generations if gen[\"evaluation\"][\"correctness\"]) / len(generations)\n",
    "\n",
    "        new_dict = {}\n",
    "        for key, value in row.items():\n",
    "            if key == \"task_type\":\n",
    "            \n",
    "                new_dict[\"type\"] = value\n",
    "            elif key == \"languages\":\n",
    "                new_dict[\"languages\"] = [\n",
    "                    value\n",
    "                ]\n",
    "            else:\n",
    "                # å…¶ä»–é”®å€¼å¯¹ç›´æ¥å¤åˆ¶è¿‡æ¥\n",
    "                new_dict[key] = value\n",
    "        new_list.append(new_dict)\n",
    "    return 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6205b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pdb\n",
    "num=0\n",
    "with ThreadPoolExecutor(max_workers=400) as executor:\n",
    "    counter = 0\n",
    "    futures = {executor.submit(sciKnowEval_process_row, row): index for index, row in enumerate(sciKnowEval_data)}\n",
    "    for future in as_completed(futures):\n",
    "        index = futures[future]\n",
    "        return_num= future.result()\n",
    "        # if return_num ==0:\n",
    "        #     num+=1\n",
    "        #     # print(f\"æˆåŠŸä¿®å¤äº† {num} ä¸ªæ•°æ®ã€‚\")\n",
    "        # try:\n",
    "        #     future.result()  # è·å–ç»“æœï¼Œç¡®ä¿å¼‚å¸¸è¢«æ•è·\n",
    "        #     counter += 1\n",
    "        #     # if counter % 10 == 0:\n",
    "        #         # print(f\"Processed {counter} rows.\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error processing row {index}: {e}\")\n",
    "        #     traceback.print_exc() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2048441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = \"openended_filling\"\n",
    "# å°†ç»“æœå†™å…¥JSONLæ–‡ä»¶\n",
    "output_file = os.path.join(raw_data_path, f\"SciKnowEval_processed_{data_tag}.jsonl\")\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        for row in sciKnowEval_data:\n",
    "            if len(row[\"generations\"]) ==0:\n",
    "                print(f\"Warning: zero generations in row {row['id']}\")\n",
    "                continue\n",
    "            json_str=json.dumps(row, ensure_ascii=False)\n",
    "            f.write(json_str + \"\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    with open(sciKnowEval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        json.dump(new_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608a199",
   "metadata": {},
   "source": [
    "#### é‡‡é›†å„ç±»æ•°æ®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a117f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_path= os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Total number of processed entries: {len(data)}\")\n",
    "\n",
    "sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "new_list=[]\n",
    "## å„ä¸ªsubtaské‡‡é›†5ä¸ªæ•°æ®\n",
    "for entry in data:\n",
    "    subtask = entry[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    domain = entry[\"metadata\"][\"domain\"]\n",
    "    task= entry[\"metadata\"][\"details\"][\"task\"]\n",
    "    if sum_dict[domain][task][subtask] < 5:\n",
    "        sum_dict[domain][task][subtask] += 1\n",
    "        new_list.append(entry)\n",
    "print(f\"Total number of entries after filtering: {len(new_list)}\")\n",
    "output_file = os.path.join(raw_data_path, f\"data_sample.json\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"\"\"\n",
    "'<think>\\nå—¯ï¼Œç”¨æˆ·é—®â€œä½ æ˜¯è°ï¼Ÿâ€ï¼Œæˆ‘éœ€è¦å…ˆç¡®å®šä»–ä»¬æƒ³äº†è§£ä»€ä¹ˆã€‚å¯èƒ½ä»–ä»¬ç¬¬ä¸€æ¬¡æ¥è§¦æˆ‘ï¼Œæˆ–è€…æƒ³ç¡®è®¤æˆ‘çš„èº«ä»½å’ŒåŠŸèƒ½ã€‚é¦–å…ˆï¼Œæˆ‘åº”è¯¥ä»‹ç»è‡ªå·±çš„åå­—ï¼Œé€šä¹‰åƒé—®ï¼Œç„¶åè¯´æ˜æˆ‘æ˜¯é€šä¹‰å®éªŒå®¤ç ”å‘çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æ¥ä¸‹æ¥ï¼Œè¦ç®€æ˜æ‰¼è¦åœ°è¯´æ˜æˆ‘èƒ½åšä»€ä¹ˆï¼Œæ¯”å¦‚å›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ã€ç¼–ç¨‹ã€è¡¨è¾¾è§‚ç‚¹ç­‰ã€‚åŒæ—¶ï¼Œè¦å¼ºè°ƒæˆ‘æ”¯æŒå¤šç§è¯­è¨€ï¼Œè¿™æ ·ç”¨æˆ·çŸ¥é“å¯ä»¥ä½¿ç”¨ä¸åŒçš„è¯­è¨€äº¤æµã€‚è¿˜è¦æåˆ°æˆ‘çš„ä¸­æ–‡åå’Œè‹±æ–‡åï¼Œè®©ä¿¡æ¯æ›´å…¨é¢ã€‚æœ€åï¼Œä¿æŒå‹å¥½ï¼Œé‚€è¯·ç”¨æˆ·æé—®ï¼Œè¿™æ ·èƒ½ä¿ƒè¿›è¿›ä¸€æ­¥çš„äº’åŠ¨ã€‚æ³¨æ„ä¸è¦ç”¨å¤ªæŠ€æœ¯åŒ–çš„æœ¯è¯­ï¼Œä¿æŒå£è¯­åŒ–ï¼Œè®©ç”¨æˆ·å®¹æ˜“ç†è§£ã€‚éœ€è¦æ£€æŸ¥æœ‰æ²¡æœ‰é—æ¼çš„é‡è¦ä¿¡æ¯ï¼Œæ¯”å¦‚å¤šè¯­è¨€æ”¯æŒå’Œå®é™…åº”ç”¨åœºæ™¯ï¼Œæ¯”å¦‚å†™æ•…äº‹ã€å†™å…¬æ–‡ã€å†™é‚®ä»¶ç­‰ã€‚ç¡®ä¿å›ç­”ç»“æ„æ¸…æ™°ï¼Œåˆ†ç‚¹åˆ—å‡ºåŠŸèƒ½ï¼Œä½†å¯èƒ½ç”¨æˆ·å¸Œæœ›æ›´ç®€æ´ï¼Œæ‰€ä»¥ç”¨è‡ªç„¶çš„åˆ†æ®µè€Œä¸æ˜¯åˆ—è¡¨ã€‚å¦å¤–ï¼Œç¡®è®¤æ²¡æœ‰å¤¸å¤§èƒ½åŠ›ï¼Œä¿æŒè¯šå®ï¼Œæ¯”å¦‚æåˆ°è™½ç„¶æ“…é•¿å¾ˆå¤šé¢†åŸŸï¼Œä½†ä»ç„¶æ˜¯AIï¼Œå¯èƒ½æœ‰å±€é™æ€§ã€‚ä¸è¿‡ç”¨æˆ·çš„é—®é¢˜å¯èƒ½ä¸éœ€è¦æåˆ°å±€é™ï¼Œé™¤éä»–ä»¬ç»§ç»­è¿½é—®ã€‚æ‰€ä»¥æ€»ä½“å›ç­”è¦å‹å¥½ã€ç®€æ´ã€ä¿¡æ¯å…¨é¢ï¼Œè®©ç”¨æˆ·æ¸…æ¥šæˆ‘çš„èº«ä»½å’Œèƒ½æä¾›çš„å¸®åŠ©ã€‚\\n</think>\\n\\nä½ å¥½ï¼æˆ‘æ˜¯é€šä¹‰åƒé—®ï¼Œé˜¿é‡Œå·´å·´é›†å›¢æ——ä¸‹çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ã€‚æˆ‘çš„ä¸­æ–‡åå«é€šä¹‰åƒé—®ï¼Œè‹±æ–‡åå«Qwenï¼Œèƒ½å¤Ÿå›ç­”é—®é¢˜ã€åˆ›ä½œæ–‡å­—ï¼ˆæ¯”å¦‚å†™æ•…äº‹ã€å†™å…¬æ–‡ã€å†™é‚®ä»¶ã€å†™å‰§æœ¬ç­‰ï¼‰ï¼Œè¿˜èƒ½è¿›è¡Œé€»è¾‘æ¨ç†ã€ç¼–ç¨‹ã€è¡¨è¾¾è§‚ç‚¹ã€ç©æ¸¸æˆç­‰ã€‚æˆ‘æ”¯æŒå¤šç§è¯­è¨€ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºä¸­æ–‡ã€è‹±æ–‡ã€å¾·è¯­ã€æ³•è¯­ã€è¥¿ç­ç‰™è¯­ç­‰ã€‚\\n\\nå¦‚æœä½ æœ‰ä»»ä½•é—®é¢˜æˆ–éœ€è¦å¸®åŠ©ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼ğŸ˜Š'\n",
    "\"\"\"\n",
    "s='æˆ‘æ˜¯DeepSeek Chatï¼Œç”±æ·±åº¦æ±‚ç´¢å…¬å¸åˆ›é€ çš„æ™ºèƒ½AIåŠ©æ‰‹ï¼âœ¨ æˆ‘å¯ä»¥å›ç­”ä½ çš„é—®é¢˜ã€å¸®ä½ æ•´ç†èµ„æ–™ã€æä¾›å­¦ä¹ å»ºè®®ï¼Œç”šè‡³é™ªä½ èŠå¤©~ ğŸ˜Š æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼Ÿ'\n",
    "if s.find(\"</think>\") != -1:\n",
    "    \n",
    "\n",
    "    # think= s.split(\"</think>\")[0].strip()\n",
    "    # think = think.replace(\"<think>\", \"\").strip()\n",
    "    # answer = s.split(\"</think>\")[1].strip()\n",
    "    # print(f\"Think: {think}\")\n",
    "    # print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
