{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e9b805",
   "metadata": {},
   "source": [
    "### 初始化全局变量，导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ff416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10300"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from model import call_huoshan,call_openai\n",
    "import pandas as pd\n",
    "import json \n",
    "if \"__file__\" in globals():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_tag=\"openended_filling\"\n",
    "sciKnowEval_path = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "if sciKnowEval_path.endswith(\".jsonl\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= [json.loads(line) for line in f if line.strip()]\n",
    "elif sciKnowEval_path.endswith(\".json\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= json.load(f)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file format: {sciKnowEval_path}\")\n",
    "len(sciKnowEval_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7451635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "750"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data = []\n",
    "count=0\n",
    "for row in sciKnowEval_data:\n",
    "    task= row[\"task\"]\n",
    "    if task==\"harmful_QA\":\n",
    "        count+=1\n",
    "        continue\n",
    "    new_data.append(row)\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61317204",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_pure.json\"), \"r\") as f:\n",
    "    sciKnowEval_score = json.load(f)\n",
    "for row in sciKnowEval_score:\n",
    "    id = row[\"id\"]\n",
    "    if id in sciKnowEval_data_dict:\n",
    "        source = sciKnowEval_data_dict[id][\"metadata\"][\"details\"][\"source\"]\n",
    "        row[\"source\"] = source\n",
    "    else:\n",
    "        print(f\"ID {id} not found in sciKnowEval_data_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89811430",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_vote.json\"), \"w\") as f:\n",
    "    json.dump(new_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff81d17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(sciKnowEval_path, \"w\") as f:\n",
    "    json.dump(sciKnowEval_data, f, indent=4, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd28430",
   "metadata": {},
   "source": [
    "#### sciKnowEval的验证器，openEnded问题使用模型验证，其余使用规则直接比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from threading import Lock\n",
    "from mpy_utils import predict_bandgap_for_structure\n",
    "import json\n",
    "import json_repair\n",
    "import os\n",
    "import sys\n",
    "import contextlib\n",
    "MPLock = Lock()\n",
    "def sciKnowEval_rule_verifier(answer_content: str,groundtruth: str, question: str, row=None):\n",
    "    \n",
    "    pattern = r\"\\\\boxed{\\\\text{(.*?)}\"\n",
    "    match = re.search(pattern, answer_content)\n",
    "\n",
    "    # 如果匹配成功，提取捕获的内容\n",
    "    if match:\n",
    "        extracted_answer = match.group(1)\n",
    "      \n",
    "    else:\n",
    "        return False\n",
    "   \n",
    "    if groundtruth.lower() == extracted_answer.lower():\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def sciKnowEval_model_verifier(question: str, groundtruth: str, model_content: str) -> bool:\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are an AI verifier. Your task is to determine if the `model_content` is a correct or acceptable response to the `question`, considering the `groundtruth` as the reference for correctness. Output only \"True\" or \"False\".\n",
    "\n",
    "[Context and Inputs Start]\n",
    "Question: {question}\n",
    "Ground Truth: {groundtruth}\n",
    "Model Content: {model_content}\n",
    "[Context and Inputs End]\n",
    "\n",
    "Evaluation Criteria:\n",
    "\n",
    "Compare the `model_content` with the `groundtruth` in the context of the `question`.\n",
    "\n",
    "\"The model_content is \"True\" if it proposes a scientifically sound and well-reasoned modification to the starting material, correctly applying one of the specified modification types from the question, and the proposed new material is a logical outcome of this modification. The rationale should clearly explain how this modification is expected to lead towards the target property. The groundtruth serves as a reference for a potentially valid outcome, but a well-argued alternative solution that also meets the question's constraints and scientific principles is also considered \"True\".\"\n",
    "\n",
    "The model_content is \"False\" if it:\n",
    "Fails to apply a valid modification type as specified in the question to the correct starting material.\n",
    "Contains critical scientific flaws in its reasoning or proposed modification.\n",
    "The proposed new material is not a logical or direct result of the described modification process.\n",
    "Fundamentally misunderstands the scientific goal or constraints of the question.\n",
    "\n",
    "Strictly output \"True\" or \"False\". Do not add any explanation or other characters.\n",
    "\n",
    "Your output is:\n",
    "\"\"\"\n",
    "\n",
    "    _,llm_response=call_openai(prompt)\n",
    "    if llm_response.strip().lower() == \"true\":\n",
    "        return True\n",
    "    elif llm_response.strip().lower() == \"false\":\n",
    "        return False\n",
    "    else:\n",
    "        print(f\"Unexpected LLM response: {llm_response}\")\n",
    "        return False \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ecd91",
   "metadata": {},
   "source": [
    "#### 处理sciKnowEval数据：生成generation，调用verifier，整合成符合要求的最终dict格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "Lock = Lock()\n",
    "new_list= []\n",
    "\n",
    "def sciKnowEval_process_row(row):\n",
    "    \n",
    "    # if len(row[\"generations\"]) >=5:\n",
    "    #     return\n",
    "    # task_type = row[\"metadata\"][\"task_type\"]\n",
    "    final_answer = row[\"ground_truth\"][\"final_answer\"]\n",
    "\n",
    "    prompt = row[\"question\"]\n",
    "    domain = row[\"metadata\"][\"domain\"]\n",
    "    subtask = row[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    \n",
    "    # generations:list= row[\"generations\"]\n",
    "    generations = row[\"generations\"] \n",
    "    # try_nums = 0\n",
    "    # while len(generations)<5: # 调用模型的次数，暂定为1\n",
    "        \n",
    "    #     generation={}\n",
    "    #     generation[\"model\"] = \"DeepSeek-R1\"\n",
    "    #     reasoning_content, answer_content = call_huoshan(prompt,\"r1\")\n",
    "    #     answer_content=answer_content.strip()\n",
    "    #     reasoning_content=reasoning_content.strip()\n",
    "\n",
    "    #     generation[\"reasoning_content\"] = reasoning_content\n",
    "    #     generation[\"answer_content\"] = answer_content\n",
    "    #     if len(answer_content) <5:\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {answer_content}|\")\n",
    "    #         try_nums += 1\n",
    "    #         if try_nums > 5:\n",
    "    #             print(f\"Warning: Too many short answer attempts in row {row['id']}. Skipping this row.\")\n",
    "    #             return\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #         continue\n",
    "    #     # Verify the model content\n",
    "    #     evaluation={}\n",
    "    \n",
    "    #     correctness = sciKnowEval_rule_verifier(answer_content,final_answer,prompt )\n",
    "    #     evaluation[\"correctness\"] = correctness\n",
    "    #     evaluation[\"By\"] = \"mengpengyu\"\n",
    "    #     evaluation[\"Method\"] =  \"Rule\"\n",
    "    #     evaluation[\"extra_tags\"] = []\n",
    "    #     generation[\"evaluation\"] = evaluation\n",
    "    #     generations.append(generation)\n",
    "        \n",
    "    # for generation in row[\"generations\"]:\n",
    "    #     if not generation[\"answer_content\"].strip():\n",
    "    #         print(f\"Warning: Short answer content detected in row {row['id']}: {generation['answer_content']}|\")\n",
    "    #         # print(f\"reasoning_content: {generation['reasoning_content']}\")\n",
    "    #     else:\n",
    "    #         generations.append(generation)\n",
    "    # row[\"generations\"] = generations\n",
    "    if len(row[\"generations\"]) <5:\n",
    "        # print(f\"Warning: Less than 5 generations in row {row['id']}. nums of generations: {len(row['generations'])}\")\n",
    "        if len(row[\"generations\"]) == 0:\n",
    "            print(f\"Warning: No generations found in row {row['id']}.\")\n",
    "            print(f\"Question: {prompt}\")\n",
    "            return 0\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    with Lock:   \n",
    "        if len(row['generations']) == 0:\n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": 0.0}\n",
    "        else:  \n",
    "            row[\"solve_rate\"] = {\"Deepseek-R1\": sum(1 for gen in row[\"generations\"] if gen[\"evaluation\"][\"correctness\"]) / len(row[\"generations\"])}\n",
    "        # row[\"generations\"]=generations\n",
    "        # row[\"solve_rate\"] = sum(1 for gen in generations if gen[\"evaluation\"][\"correctness\"]) / len(generations)\n",
    "\n",
    "        new_dict = {}\n",
    "        for key, value in row.items():\n",
    "            if key == \"task_type\":\n",
    "            \n",
    "                new_dict[\"type\"] = value\n",
    "            elif key == \"languages\":\n",
    "                new_dict[\"languages\"] = [\n",
    "                    value\n",
    "                ]\n",
    "            else:\n",
    "                # 其他键值对直接复制过来\n",
    "                new_dict[key] = value\n",
    "        new_list.append(new_dict)\n",
    "    return 0\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6205b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import pdb\n",
    "num=0\n",
    "with ThreadPoolExecutor(max_workers=400) as executor:\n",
    "    counter = 0\n",
    "    futures = {executor.submit(sciKnowEval_process_row, row): index for index, row in enumerate(sciKnowEval_data)}\n",
    "    for future in as_completed(futures):\n",
    "        index = futures[future]\n",
    "        return_num= future.result()\n",
    "        # if return_num ==0:\n",
    "        #     num+=1\n",
    "        #     # print(f\"成功修复了 {num} 个数据。\")\n",
    "        # try:\n",
    "        #     future.result()  # 获取结果，确保异常被捕获\n",
    "        #     counter += 1\n",
    "        #     # if counter % 10 == 0:\n",
    "        #         # print(f\"Processed {counter} rows.\")\n",
    "        # except Exception as e:\n",
    "        #     print(f\"Error processing row {index}: {e}\")\n",
    "        #     traceback.print_exc() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2048441",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tag = \"openended_filling\"\n",
    "# 将结果写入JSONL文件\n",
    "output_file = os.path.join(raw_data_path, f\"SciKnowEval_processed_{data_tag}.jsonl\")\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        for row in sciKnowEval_data:\n",
    "            if len(row[\"generations\"]) ==0:\n",
    "                print(f\"Warning: zero generations in row {row['id']}\")\n",
    "                continue\n",
    "            json_str=json.dumps(row, ensure_ascii=False)\n",
    "            f.write(json_str + \"\\n\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fb1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    with open(sciKnowEval_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        json.dump(new_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    hash(\"abc\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c608a199",
   "metadata": {},
   "source": [
    "#### 采集各类数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a117f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_path= os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(f\"Total number of processed entries: {len(data)}\")\n",
    "\n",
    "sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "new_list=[]\n",
    "## 各个subtask采集5个数据\n",
    "for entry in data:\n",
    "    subtask = entry[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    domain = entry[\"metadata\"][\"domain\"]\n",
    "    task= entry[\"metadata\"][\"details\"][\"task\"]\n",
    "    if sum_dict[domain][task][subtask] < 5:\n",
    "        sum_dict[domain][task][subtask] += 1\n",
    "        new_list.append(entry)\n",
    "print(f\"Total number of entries after filtering: {len(new_list)}\")\n",
    "output_file = os.path.join(raw_data_path, f\"data_sample.json\")\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_list, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527d8828",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"\"\"\n",
    "'<think>\\n嗯，用户问“你是谁？”，我需要先确定他们想了解什么。可能他们第一次接触我，或者想确认我的身份和功能。首先，我应该介绍自己的名字，通义千问，然后说明我是通义实验室研发的超大规模语言模型。接下来，要简明扼要地说明我能做什么，比如回答问题、创作文字、编程、表达观点等。同时，要强调我支持多种语言，这样用户知道可以使用不同的语言交流。还要提到我的中文名和英文名，让信息更全面。最后，保持友好，邀请用户提问，这样能促进进一步的互动。注意不要用太技术化的术语，保持口语化，让用户容易理解。需要检查有没有遗漏的重要信息，比如多语言支持和实际应用场景，比如写故事、写公文、写邮件等。确保回答结构清晰，分点列出功能，但可能用户希望更简洁，所以用自然的分段而不是列表。另外，确认没有夸大能力，保持诚实，比如提到虽然擅长很多领域，但仍然是AI，可能有局限性。不过用户的问题可能不需要提到局限，除非他们继续追问。所以总体回答要友好、简洁、信息全面，让用户清楚我的身份和能提供的帮助。\\n</think>\\n\\n你好！我是通义千问，阿里巴巴集团旗下的超大规模语言模型。我的中文名叫通义千问，英文名叫Qwen，能够回答问题、创作文字（比如写故事、写公文、写邮件、写剧本等），还能进行逻辑推理、编程、表达观点、玩游戏等。我支持多种语言，包括但不限于中文、英文、德语、法语、西班牙语等。\\n\\n如果你有任何问题或需要帮助，随时告诉我！😊'\n",
    "\"\"\"\n",
    "s='我是DeepSeek Chat，由深度求索公司创造的智能AI助手！✨ 我可以回答你的问题、帮你整理资料、提供学习建议，甚至陪你聊天~ 😊 有什么我可以帮你的吗？'\n",
    "if s.find(\"</think>\") != -1:\n",
    "    \n",
    "\n",
    "    # think= s.split(\"</think>\")[0].strip()\n",
    "    # think = think.replace(\"<think>\", \"\").strip()\n",
    "    # answer = s.split(\"</think>\")[1].strip()\n",
    "    # print(f\"Think: {think}\")\n",
    "    # print(f\"Answer: {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
