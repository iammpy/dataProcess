{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e9b805",
   "metadata": {},
   "source": [
    "### 初始化全局变量，导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "610ff416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from model import call_huoshan,call_openai\n",
    "import pandas as pd\n",
    "if \"__file__\" in globals():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "scienceQA_path = os.path.join(raw_data_path, \"ScienceQA\")\n",
    "sciKnowEval_path = os.path.join(raw_data_path, \"SciKnowEval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673aa773",
   "metadata": {},
   "source": [
    "### 查看并读取sciQA数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f62c49b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath: /u01/mengpengyu/dataProcess/sciknowevalProcess.ipynb\n",
    "\n",
    "sciQA_path=[]\n",
    "sciQA_path.append(os.path.join(scienceQA_path, \"test-00000-of-00001-f0e719df791966ff.parquet\"))\n",
    "sciQA_path.append(os.path.join(scienceQA_path, \"train-00000-of-00001-1028f23e353fbe3e.parquet\"))\n",
    "sciQA_path.append(os.path.join(scienceQA_path, \"validation-00000-of-00001-6c7328ff6c84284c.parquet\"))\n",
    "\n",
    "all_dfs = []\n",
    "for file_path in sciQA_path:\n",
    "    temp_df = pd.read_parquet(file_path)\n",
    "    all_dfs.append(temp_df)\n",
    "\n",
    "sciQA_data = pd.concat(all_dfs, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3542e2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_output_dir = os.path.join(raw_data_path, \"ScienceQA\", \"images\")\n",
    "os.makedirs(image_output_dir, exist_ok=True) # 如果文件夹不存在则创建\n",
    "\n",
    "def save_image(row, id):\n",
    "    if row[\"image\"] is not None and isinstance(row[\"image\"], dict) and \"bytes\" in row[\"image\"]:\n",
    "        image_bytes = row['image']['bytes']\n",
    "        if image_bytes: # 确保字节数据不为空\n",
    "            # 构建图片文件名，可以使用索引 i 或者其他唯一标识符\n",
    "            # 假设图片是 png 格式，如果不是，需要根据实际情况调整扩展名\n",
    "            image_filename = f\"image_{id}.png\"\n",
    "            image_filepath = os.path.join(image_output_dir, image_filename)\n",
    "            \n",
    "            try:\n",
    "                with open(image_filepath, \"wb\") as img_file: # \"wb\" 表示以二进制写入模式打开\n",
    "                    img_file.write(image_bytes)\n",
    "                # print(f\"Saved image to {image_filepath}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving image {image_filepath}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e585b6eb",
   "metadata": {},
   "source": [
    "#### 根据一个问题，以及不同的文件类型，构建传给模型的最终prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223bd79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def sciQA_build_prompt(row):\n",
    "    question = row[\"question\"]\n",
    "    choices = row[\"choices\"]\n",
    "    hint= row[\"hint\"]\n",
    "    formatted_options = []\n",
    "    for i, option_text in enumerate(choices):\n",
    "        formatted_options.append(f'({i}): {option_text}') # 注意这里选项文本也被引号包围了\n",
    "    choices_with_indices = \"\\n\".join(formatted_options)\n",
    "    prompt=f\"\"\"\n",
    "Review the question and the options provided below. Each option is clearly labeled with its numerical index.\n",
    "Select the option that best answers the question.\n",
    "Respond with ONLY the numerical index label of your chosen option.\n",
    "Your entire response must be a single integer. Do not include any other text or explanations.\n",
    "Input (Optional, for reference only, may be empty or not needed):\n",
    "{hint} \n",
    "Question:\n",
    "{question}\n",
    "Options:\n",
    "{choices_with_indices}\n",
    "Answer Index:\n",
    "    \"\"\"\n",
    "    # prompt=f\"\"\"\n",
    "    # 关于下面这些问题，我注意到有些问题的选项可能不完整或不准确。这个数据集是有三个字段，question、choices和hint。\n",
    "    # 正常来说hint是用来提示问题的，但是对于某些question，hint可能就是上下文，缺少hint这个问题无法回答。\n",
    "    # 我在下面给你每个问题的question、choices和hint，请你判断hint是否是回答这个问题所必须的。(注意，这里的必须指的是缺少hint这个无法通过任何推理选出某个选项)\n",
    "    # 如果是，则返回\"yes\"，否则返回\"no\"，如果提供给你的hint是空的，则返回\"null\"\n",
    "    # Question:\n",
    "    # {question}\n",
    "    # Choices:\n",
    "    # {choices_with_indices}\n",
    "    # Hint:\n",
    "    # {hint}\n",
    "    # 注意，回答只能是yes，或者no，或者null，不要包含其他任何字符。\n",
    "    # Is the hint necessary to answer the question? (yes/no/null):\n",
    "    # \"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6e611d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib\n",
    "\n",
    "def generate_md5(input_string):\n",
    "    # 创建一个 md5 hash 对象\n",
    "    md5_hash = hashlib.md5()\n",
    "    \n",
    "    # 将输入的字符串转换为字节串（因为 hashlib 需要字节类型的数据）\n",
    "    input_bytes = input_string.encode('utf-8')\n",
    "    \n",
    "    # 更新哈希对象\n",
    "    md5_hash.update(input_bytes)\n",
    "    \n",
    "    # 获取哈希值的十六进制表示\n",
    "    md5_digest = md5_hash.hexdigest()\n",
    "    \n",
    "    return md5_digest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd28430",
   "metadata": {},
   "source": [
    "#### 都是选择题，直接使用规则比对"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7c89d68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sciQA_rule_verifier(question, groundtruth, model_content):\n",
    "    if groundtruth == model_content:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ecd91",
   "metadata": {},
   "source": [
    "#### 处理sciQA数据：生成generation，调用verifier，整合成符合要求的最终dict格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c05e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import numpy as np\n",
    "Lock = Lock()\n",
    "\n",
    "\n",
    "def sciKnowEval_process_row(row):\n",
    "    global res_list\n",
    "    global res_list_with_image\n",
    "\n",
    "   \n",
    "    groundtruth = str(row[\"answer\"])\n",
    "\n",
    "    prompt = sciQA_build_prompt(row)\n",
    "    id =generate_md5(prompt)\n",
    "    generations=[]\n",
    "    if row[\"image\"] is not None and isinstance(row[\"image\"], dict) and \"bytes\" in row[\"image\"]:\n",
    "        save_image(row, id)\n",
    "        \n",
    "    elif row[\"image\"] is None :\n",
    "        # If no image, use the model to generate the answer\n",
    "        for i in range(1): # 调用模型的次数，暂定为1\n",
    "            generation={}\n",
    "            generation[\"model\"] = \"DeepSeek-R1\"\n",
    "            reasoning_content, answer_content = call_huoshan(prompt,\"r1\")\n",
    "            answer_content=answer_content.strip()\n",
    "            generation[\"reasoning_content\"] = reasoning_content\n",
    "            generation[\"answer_content\"] = answer_content\n",
    "            # Verify the model content\n",
    "            evaluation={}\n",
    "            correctness = sciQA_rule_verifier(prompt, groundtruth, answer_content)\n",
    "            \n",
    "            evaluation[\"correctness\"] = correctness\n",
    "            evaluation[\"By\"] = \"mengpengyu\"\n",
    "            evaluation[\"Method\"] = \"Rule\"\n",
    "            evaluation[\"extra_tags\"] = []\n",
    "            generation[\"evaluation\"] = evaluation\n",
    "            generations.append(generation)\n",
    "\n",
    "\n",
    "    task_type= \"multiple_choice_single\"\n",
    "    # 删除image字段\n",
    "    if row[\"image\"] is not None:\n",
    "        row[\"image\"]=f\"image_{id}.png\"  # 将图片字段替换为图片文件名\n",
    "    cleaned_metadata = {}\n",
    "    for key, value in row.items():\n",
    "        if isinstance(value, np.ndarray):\n",
    "            cleaned_metadata[key] = value.tolist()  # 将 ndarray 转换为 list\n",
    "        elif isinstance(value, np.generic): # 处理 NumPy 标量类型如 np.int64, np.float64\n",
    "            cleaned_metadata[key] = value.item()\n",
    "        else:\n",
    "            cleaned_metadata[key] = value\n",
    "    res_dict={}\n",
    "    res_dict[\"id\"] = id\n",
    "    res_dict[\"metadata\"] = cleaned_metadata\n",
    "    res_dict[\"source_dataset\"] = \"derek-thomas/ScienceQA\"\n",
    "    # res_dict[\"subject_info\"] = row[\"domain\"]   #待定，额外对数据进行打标？\n",
    "    res_dict[\"task_type\"] = task_type\n",
    "    res_dict[\"languages\"] = \"en\"\n",
    "    if row[\"image\"] is not None:\n",
    "        res_dict[\"multimedia\"]= [{\n",
    "            \"type\": \"image\",\n",
    "            \"content\": f\"ScienceQA/images/{row['image']}\"\n",
    "        }]\n",
    "    res_dict[\"question\"] = prompt\n",
    "    res_dict[\"ground_truth\"] = {\n",
    "            \"final_answer\": groundtruth,\n",
    "            \"unit\": None, \n",
    "            \"solution\": None,\n",
    "            \"extra_tags\": []\n",
    "        }\n",
    "    res_dict[\"generations\"]=generations\n",
    "    if len(generations) == 0:\n",
    "        res_dict[\"solve_rate\"] = None\n",
    "    else:\n",
    "        res_dict[\"solve_rate\"] = sum(1 for gen in generations if gen[\"evaluation\"][\"correctness\"]) / len(generations)\n",
    "    res_dict[\"prompted_for_correct_answer\"]= False\n",
    "    with Lock:\n",
    "        if row[\"image\"] is not None:\n",
    "            res_list_with_image.append(res_dict)\n",
    "        else:\n",
    "            res_list.append(res_dict)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c6205b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 10 rows.\n",
      "Processed 20 rows.\n",
      "Processed 30 rows.\n",
      "Processed 40 rows.\n",
      "Processed 50 rows.\n",
      "Processed 60 rows.\n",
      "Processed 70 rows.\n",
      "Processed 80 rows.\n",
      "Processed 90 rows.\n",
      "Processed 100 rows.\n",
      "Processed 110 rows.\n",
      "Processed 120 rows.\n",
      "Processed 130 rows.\n",
      "Processed 140 rows.\n",
      "Processed 150 rows.\n",
      "Processed 160 rows.\n",
      "Processed 170 rows.\n",
      "Processed 180 rows.\n",
      "Processed 190 rows.\n",
      "Processed 200 rows.\n",
      "Processed 210 rows.\n",
      "Processed 220 rows.\n",
      "Processed 230 rows.\n",
      "Processed 240 rows.\n",
      "Processed 250 rows.\n",
      "Processed 260 rows.\n",
      "Processed 270 rows.\n",
      "Processed 280 rows.\n",
      "Processed 290 rows.\n",
      "Processed 300 rows.\n",
      "Processed 310 rows.\n",
      "Processed 320 rows.\n",
      "Processed 330 rows.\n",
      "Processed 340 rows.\n",
      "Processed 350 rows.\n",
      "Processed 360 rows.\n",
      "Processed 370 rows.\n",
      "Processed 380 rows.\n",
      "Processed 390 rows.\n",
      "Processed 400 rows.\n",
      "Processed 410 rows.\n",
      "Processed 420 rows.\n",
      "Processed 430 rows.\n",
      "Processed 440 rows.\n",
      "Processed 450 rows.\n",
      "Processed 460 rows.\n",
      "Processed 470 rows.\n",
      "Processed 480 rows.\n",
      "Processed 490 rows.\n",
      "Processed 500 rows.\n",
      "Processed 510 rows.\n",
      "Processed 520 rows.\n",
      "Processed 530 rows.\n",
      "Processed 540 rows.\n",
      "Processed 550 rows.\n",
      "Processed 560 rows.\n",
      "Processed 570 rows.\n",
      "Processed 580 rows.\n",
      "Processed 590 rows.\n",
      "Processed 600 rows.\n",
      "Processed 610 rows.\n",
      "Processed 620 rows.\n",
      "Processed 630 rows.\n",
      "Processed 640 rows.\n",
      "Processed 650 rows.\n",
      "Processed 660 rows.\n",
      "Processed 670 rows.\n",
      "Processed 680 rows.\n",
      "Processed 690 rows.\n",
      "Processed 700 rows.\n",
      "Processed 710 rows.\n",
      "Processed 720 rows.\n",
      "Processed 730 rows.\n",
      "Processed 740 rows.\n",
      "Processed 750 rows.\n",
      "Processed 760 rows.\n",
      "Processed 770 rows.\n",
      "Processed 780 rows.\n",
      "Processed 790 rows.\n",
      "Processed 800 rows.\n",
      "Processed 810 rows.\n",
      "Processed 820 rows.\n",
      "Processed 830 rows.\n",
      "Processed 840 rows.\n",
      "Processed 850 rows.\n",
      "Processed 860 rows.\n",
      "Processed 870 rows.\n",
      "Processed 880 rows.\n",
      "Processed 890 rows.\n",
      "Processed 900 rows.\n",
      "Processed 910 rows.\n",
      "Processed 920 rows.\n",
      "Processed 930 rows.\n",
      "Processed 940 rows.\n",
      "Processed 950 rows.\n",
      "Processed 960 rows.\n",
      "Processed 970 rows.\n",
      "Processed 980 rows.\n",
      "Processed 990 rows.\n",
      "Processed 1000 rows.\n",
      "Results written to raw_data/ScienceQA_processed.json\n",
      "Results with images written to raw_data/ScienceQA_processed_with_image.json\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pdb\n",
    "res_list = []\n",
    "res_list_with_image = []\n",
    "with ThreadPoolExecutor(max_workers=200) as executor:\n",
    "    counter = 0\n",
    "    futures = {executor.submit(sciKnowEval_process_row, row): index for index, row in sciQA_data.iloc[500:1500].iterrows()}\n",
    "    for future in as_completed(futures):\n",
    "        index = futures[future]\n",
    "        try:\n",
    "            future.result()  # 获取结果，确保异常被捕获\n",
    "            counter += 1\n",
    "            if counter % 10 == 0:\n",
    "                print(f\"Processed {counter} rows.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            traceback.print_exc() \n",
    "# 将结果写入JSON文件\n",
    "output_file = os.path.join(raw_data_path, \"ScienceQA_processed.json\")\n",
    "output_file_with_image = os.path.join(raw_data_path, \"ScienceQA_processed_with_image.json\")\n",
    "try:\n",
    "    with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(res_list, f, ensure_ascii=False, indent=4)   \n",
    "        print(f\"Results written to {output_file}\")\n",
    "    with open(output_file_with_image, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(res_list_with_image, f, ensure_ascii=False, indent=4)   \n",
    "        print(f\"Results with images written to {output_file_with_image}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {output_file}: {e}\")\n",
    "    pdb.set_trace()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
