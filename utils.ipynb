{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mp_api.client import MPRester\n",
    "import os\n",
    "\n",
    "API_KEY = \"bSpFQg1jCJpFG4CARe0NiSUyXKke56OF\"  # <--- 在这里替换成您的密钥\n",
    "formula_to_search = \"LiAlPO4F\"\n",
    "\n",
    "print(f\"开始对 {formula_to_search} 进行分步查询...\")\n",
    "\n",
    "try:\n",
    "    with MPRester(api_key=API_KEY) as mpr:\n",
    "\n",
    "        # --- 步骤 1: 查询热力学性质，找到最稳定的材料 ID ---\n",
    "        # 我们先从热力学端点入手，因为稳定性是首要关心的\n",
    "        print(\"\\n步骤 1: 查询热力学性质以确定最稳定的结构...\")\n",
    "        thermo_docs = mpr.thermo.search(\n",
    "            formula=formula_to_search,\n",
    "            fields=[\"material_id\", \"energy_above_hull\", \"formula_pretty\"]\n",
    "        )\n",
    "\n",
    "        if not thermo_docs:\n",
    "            raise ValueError(f\"在热力学数据库中未找到关于 {formula_to_search} 的材料。\")\n",
    "\n",
    "        # 按稳定性（energy_above_hull）排序，找到最稳定的那个\n",
    "        stable_thermo_docs = sorted(thermo_docs, key=lambda doc: doc.energy_above_hull)\n",
    "        most_stable_thermo_doc = stable_thermo_docs[0]\n",
    "        \n",
    "        # 获取最稳定结构的 material_id，这是我们接下来查询的“钥匙”\n",
    "        stable_material_id = most_stable_thermo_doc.material_id\n",
    "        energy_above_hull = most_stable_thermo_doc.energy_above_hull\n",
    "        pretty_formula = most_stable_thermo_doc.formula_pretty\n",
    "\n",
    "        print(f\"找到最稳定结构 ID: {stable_material_id} (稳定性: {energy_above_hull:.3f} eV/atom)\")\n",
    "\n",
    "        # --- 步骤 2: 使用最稳定的 ID 查询电子结构性质（如带隙） ---\n",
    "        print(\"\\n步骤 2: 使用稳定结构 ID 查询电子结构性质...\")\n",
    "        es_doc = mpr.electronic_structure.search(\n",
    "            material_ids=[stable_material_id],\n",
    "            fields=[\"material_id\", \"band_gap\"]\n",
    "        )\n",
    "        \n",
    "        # es_doc 返回的是列表，我们取第一个\n",
    "        band_gap = es_doc[0].band_gap if es_doc else None\n",
    "\n",
    "        # --- 步骤 3: 使用最稳定的 ID 查询其他结构性质 ---\n",
    "        print(\"\\n步骤 3: 使用稳定结构 ID 查询结构性质...\")\n",
    "        mat_doc = mpr.materials.search(\n",
    "            material_ids=[stable_material_id],\n",
    "            fields=[\"volume\", \"density\", \"symmetry\"]\n",
    "        )\n",
    "        \n",
    "        # mat_doc 返回的是列表，我们取第一个\n",
    "        volume = mat_doc[0].volume if mat_doc else None\n",
    "        density = mat_doc[0].density if mat_doc else None\n",
    "        crystal_system = mat_doc[0].symmetry.crystal_system.value if mat_doc else None\n",
    "\n",
    "        # --- 步骤 4: 汇总并打印所有信息 ---\n",
    "        print(\"\\n--- 查询完成！汇总所有信息 ---\")\n",
    "        print(f\"材料 ID (Material ID): {stable_material_id}\")\n",
    "        print(f\"化学式 (Formula): {pretty_formula}\")\n",
    "        print(f\"晶系 (Crystal System): {crystal_system}\")\n",
    "        print(f\"晶胞体积 (Volume): {volume:.2f} Å³\" if volume else \"N/A\")\n",
    "        print(f\"密度 (Density): {density:.2f} g/cm³\" if density else \"N/A\")\n",
    "        print(f\"稳定性 (Energy Above Hull): {energy_above_hull:.3f} eV/atom\")\n",
    "        \n",
    "        if band_gap is not None:\n",
    "            if band_gap > 0:\n",
    "                print(f\"带隙 (Band Gap): {band_gap:.3f} eV (这是一个半导体或绝缘体)\")\n",
    "            else:\n",
    "                print(f\"带隙 (Band Gap): {band_gap:.3f} eV (这是一个金属)\")\n",
    "        else:\n",
    "            print(\"带隙 (Band Gap): 未提供或查询失败\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n查询过程中发生错误: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2104417e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from mp_api.client import MPRester\n",
    "import matgl\n",
    "from matgl.ext.pymatgen import Structure2Graph\n",
    "\n",
    "# --- 第 0, 1, 2 部分代码保持不变 ---\n",
    "# ... (省略前面的代码) ...\n",
    "# --- 第 0 部分: 配置 ---\n",
    "API_KEY = \"bSpFQg1jCJpFG4CARe0NiSUyXKke56OF\"  # <--- 在这里替换成您的密钥\n",
    "MATERIAL_ID = \"mp-1210463\" \n",
    "\n",
    "print(\"--- 开始执行材料性质预测工作流 ---\")\n",
    "\n",
    "# --- 第一步: 获取晶体结构 ---\n",
    "print(f\"\\n步骤 1: 正在从 Materials Project 获取 {MATERIAL_ID} 的晶体结构...\")\n",
    "structure = None\n",
    "try:\n",
    "    with MPRester(api_key=API_KEY) as mpr:\n",
    "        docs = mpr.materials.search(material_ids=[MATERIAL_ID], fields=[\"structure\"])\n",
    "        if docs:\n",
    "            structure = docs[0].structure\n",
    "            print(\"晶体结构获取成功！\")\n",
    "        else:\n",
    "            print(f\"错误: 无法找到 ID 为 {MATERIAL_ID} 的材料。\")\n",
    "            exit()\n",
    "except Exception as e:\n",
    "    print(f\"从 Materials Project 获取数据时出错: {e}\")\n",
    "    exit()\n",
    "\n",
    "\n",
    "# --- 第二步: 加载 MATGL 预训练模型 ---\n",
    "model_name = \"MEGNet-MP-2019.4.1-BandGap-mfi\"\n",
    "print(f\"\\n步骤 2: 正在加载 MATGL 模型 '{model_name}'...\")\n",
    "model = matgl.load_model(model_name)\n",
    "print(\"模型加载成功！\")\n",
    "\n",
    "\n",
    "# --- 第三步: 将结构转换为图，并进行必要的修正 ---\n",
    "if structure:\n",
    "    print(f\"\\n步骤 3: 正在将晶体结构转换为图并修正数据...\")\n",
    "    \n",
    "    converter = Structure2Graph(element_types=model.model.element_types, cutoff=5.0)\n",
    "    \n",
    "    # get_graph 返回一个元组，我们只需要第一个元素，即图对象 g\n",
    "    g = converter.get_graph(structure)[0] \n",
    "    \n",
    "    # 修正数据类型\n",
    "    if 'node_type' in g.ndata and g.ndata['node_type'].dtype != torch.long:\n",
    "        g.ndata['node_type'] = g.ndata['node_type'].to(torch.long)\n",
    "\n",
    "    # 修正节点数据键名\n",
    "    if 'frac_coords' in g.ndata:\n",
    "        g.ndata['pos'] = g.ndata.pop('frac_coords')\n",
    "\n",
    "    # 修正边数据键名\n",
    "    if 'pbc_offset' in g.edata:\n",
    "        g.edata['pbc_offshift'] = g.edata.pop('pbc_offset')\n",
    "    \n",
    "    print(\"数据准备完成！\")\n",
    "\n",
    "    # --- 第四步: 使用图对象进行预测 ---\n",
    "    print(f\"\\n步骤 4: 正在对 {structure.formula} ({MATERIAL_ID}) 进行带隙预测...\")\n",
    "    \n",
    "    # ####################################################################\n",
    "    #\n",
    "    #   最 终 关 键 修 正\n",
    "    #   调用模型时，不再传递 state_attr 参数\n",
    "    #\n",
    "    # ####################################################################\n",
    "    predicted_band_gap = model(g)\n",
    "    \n",
    "    band_gap_value = predicted_band_gap.item()\n",
    "    \n",
    "    print(\"\\n--- 预测完成 ---\")\n",
    "    print(f\"MATGL 模型预测的带隙为: {band_gap_value:.3f} eV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8522f4dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matgl\n",
    "from pymatgen.core import Lattice, Structure\n",
    "\n",
    "# --- 步骤 1: 创建一个晶体结构作为输入 ---\n",
    "# 这里我们使用官方文档中的 CsCl 结构作为示例。\n",
    "# 您的任何其他 pymatgen 结构对象都可以替换这里的 'struct'。\n",
    "print(\"正在创建 CsCl 晶体结构...\")\n",
    "struct = Structure.from_spacegroup(\n",
    "    \"Pm-3m\", Lattice.cubic(4.1437), [\"Cs\", \"Cl\"], [[0, 0, 0], [0.5, 0.5, 0.5]]\n",
    ")\n",
    "print(\"结构创建成功。\")\n",
    "\n",
    "# --- 步骤 2: 加载预训练的带隙预测模型 ---\n",
    "# 我们加载文档中指定的、需要额外条件（state_attr）的多保真度模型。\n",
    "model_name = \"MEGNet-MP-2019.4.1-BandGap-mfi\"\n",
    "print(f\"正在加载模型 '{model_name}'...\")\n",
    "model = matgl.load_model(model_name)\n",
    "print(\"模型加载成功。\")\n",
    "\n",
    "# --- 步骤 3: 进行预测 ---\n",
    "# 对于这个特殊的多保真度模型，我们需要提供一个 state_attr 来选择预测哪种计算精度的带隙。\n",
    "# 0 代表 PBE 精度，这是最常用的一种。\n",
    "state_attr_for_pbe = torch.tensor([0])\n",
    "print(\"正在使用 PBE 精度 (state_attr = 0) 进行带隙预测...\")\n",
    "\n",
    "# 直接调用高级预测接口 predict_structure\n",
    "predicted_band_gap = model.predict_structure(\n",
    "    structure=struct, \n",
    "    state_attr=state_attr_for_pbe\n",
    ")\n",
    "\n",
    "# --- 最终结果 ---\n",
    "# 使用 .item() 从结果张量中提取出纯数字\n",
    "band_gap_value = predicted_band_gap.item()\n",
    "\n",
    "print(\"\\n--- 预测完成 ---\")\n",
    "print(f\"模型预测的 CsCl (PBE) 带隙为: {band_gap_value:.3f} eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69d501c",
   "metadata": {},
   "source": [
    "### 提取材料学中几个open-ended类型的数据各50条进行标注"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297a931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import defaultdict\n",
    "import os\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "data_path= os.path.join(raw_data_path, \"SciKnowEval_processed_tag.json\")\n",
    "\n",
    "num_dict = defaultdict(int)\n",
    "# 读取 JSON 文件\n",
    "data_path= os.path.join(raw_data_path, \"SciKnowEval_processed.json\")\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    data = json.load(file)\n",
    "output_list = []\n",
    "# 遍历数据\n",
    "for item in data:\n",
    "    if item[\"metadata\"][\"domain\"]==\"Material\":\n",
    "        subtask = item[\"metadata\"][\"details\"][\"subtask\"]\n",
    "        if subtask==\"material_component_extraction\" \\\n",
    "        or subtask==   \"property_and_usage_analysis\":\n",
    "        \n",
    "        # or subtask== \"crystal_structure_and_composition_analysis\"\\\n",
    "            # 统计子任务出现的次数\n",
    "            if num_dict[subtask]<50:\n",
    "                num_dict[subtask] += 1\n",
    "                # 将 item 添加到输出列表\n",
    "                item[\"generations\"][0][\"evaluation\"][\"tag\"]=item[\"generations\"][0][\"evaluation\"][\"correctness\"]\n",
    "                output_list.append(item)\n",
    "# 将输出列表写入新的 JSON 文件\n",
    "output_path = os.path.join(raw_data_path, \"SciKnowEval_processed_tag.json\")\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(output_list, file, ensure_ascii=False, indent=4)\n",
    "            \n",
    "       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc04723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mp_api.client import MPRester\n",
    "\n",
    "# --- 配置您的 API 密钥 ---\n",
    "# 强烈建议将密钥设置为环境变量 MP_API_KEY\n",
    "# 如果已经设置，MPRester() 会自动读取，无需传入参数\n",
    "API_KEY = \"bSpFQg1jCJpFG4CARe0NiSUyXKke56OF\"  # <--- 请在这里替换成您自己的密钥\n",
    "\n",
    "# 目标化学式\n",
    "formula_to_search = \"LiFePO4F\"\n",
    "\n",
    "print(f\"--- 步骤 1: 获取 {formula_to_search} 的晶体结构 ---\")\n",
    "print(\"正在连接 Materials Project 数据库...\")\n",
    "\n",
    "# 将最终的 pymatgen Structure 对象保存在这里\n",
    "LiFePO4F_structure = None\n",
    "\n",
    "try:\n",
    "    with MPRester(api_key=API_KEY) as mpr:\n",
    "        # 首先，从热力学端点查询，找到最稳定的材料ID\n",
    "        print(f\"正在查询 {formula_to_search} 的热力学稳定性...\")\n",
    "        thermo_docs = mpr.thermo.search(\n",
    "            formula=formula_to_search,\n",
    "            fields=[\"material_id\", \"energy_above_hull\", \"formula_pretty\"]\n",
    "        )\n",
    "\n",
    "        if not thermo_docs:\n",
    "            raise ValueError(f\"在热力学数据库中未找到关于 {formula_to_search} 的材料。\")\n",
    "\n",
    "        # 按稳定性排序，找到能量最低的（最稳定的）条目\n",
    "        stable_thermo_docs = sorted(thermo_docs, key=lambda doc: doc.energy_above_hull)\n",
    "        most_stable_entry = stable_thermo_docs[0]\n",
    "        \n",
    "        stable_material_id = most_stable_entry.material_id\n",
    "        stability = most_stable_entry.energy_above_hull\n",
    "\n",
    "        print(f\"已找到最稳定的结构: {stable_material_id} (稳定性 E-above-hull: {stability:.3f} eV/atom)\")\n",
    "\n",
    "        # 然后，使用最稳定的ID去获取其详细的晶体结构\n",
    "        print(f\"正在使用 ID ({stable_material_id}) 获取详细结构...\")\n",
    "        structure_docs = mpr.materials.search(\n",
    "            material_ids=[stable_material_id], \n",
    "            fields=[\"structure\"]\n",
    "        )\n",
    "        \n",
    "        if structure_docs:\n",
    "            LiFePO4F_structure = structure_docs[0].structure\n",
    "            print(\"晶体结构获取成功！\")\n",
    "        else:\n",
    "            raise ValueError(f\"无法使用ID {stable_material_id} 获取结构信息。\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n查询过程中发生错误: {e}\")\n",
    "\n",
    "# --- 打印最终获取的结构信息 ---\n",
    "if LiFePO4F_structure:\n",
    "    print(\"\\n--- LiFePO4F (最稳定结构) 详细信息 ---\")\n",
    "    print(LiFePO4F_structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e62995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from mp_api.client import MPRester\n",
    "import matgl\n",
    "from matgl.ext.pymatgen import Structure2Graph\n",
    "from  matgl.ext.ase import Relaxer # 导入专门用于结构弛豫的工具\n",
    "\n",
    "# ==============================================================================\n",
    "# 步骤 1: 一次性加载所有需要的模型\n",
    "# ==============================================================================\n",
    "print(\"--- 正在加载所有必需的 MATGL 模型 ---\")\n",
    "\n",
    "pes_model = matgl.load_model(\"CHGNet-MPtrj-2024.2.13-11M-PES\")\n",
    "print(\"势能面 (PES) 模型加载成功！\")\n",
    "\n",
    "bandgap_model_wrapper = matgl.load_model(\"MEGNet-MP-2019.4.1-BandGap-mfi\")\n",
    "bandgap_model = bandgap_model_wrapper.model \n",
    "element_types = bandgap_model.element_types\n",
    "print(\"带隙 (BandGap) 模型加载成功！\")\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 步骤 2: 定义一个可重复使用的、稳健的预测函数\n",
    "# ==============================================================================\n",
    "def predict_property_for_modified_structure(\n",
    "    initial_structure,\n",
    "    modification_type: str,\n",
    "    modification_details: dict,\n",
    "    potential_model, \n",
    "    property_model,\n",
    "):\n",
    "    \"\"\"\n",
    "    一个通用的函数，用于修改结构、进行弛豫，并预测最终性质。\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- 开始处理新任务：对 {initial_structure.composition.reduced_formula} 进行 {modification_type} 操作 ---\")\n",
    "    \n",
    "    # --- 2.1. 根据指令修改结构 ---\n",
    "    print(\"步骤 2.1: 正在应用原子修改...\")\n",
    "    modified_structure = initial_structure.copy()\n",
    "    \n",
    "    if modification_type == \"substitute\":\n",
    "        from_el = modification_details[\"from\"]\n",
    "        to_el = modification_details[\"to\"]\n",
    "        modified_structure.replace_species({from_el: to_el})\n",
    "        print(f\"已将 {from_el} 替换为 {to_el}。新化学式: {modified_structure.composition.reduced_formula}\")\n",
    "    # ... (可以补充 'remove', 'add' 等其他修改类型的逻辑)\n",
    "    else:\n",
    "        raise ValueError(f\"不支持的修改类型: {modification_type}\")\n",
    "\n",
    "    # --- 2.2. 对新结构进行弛豫，找到稳定构型 ---\n",
    "    print(\"步骤 2.2: 正在使用 PES 模型进行结构弛豫...\")\n",
    "    relaxer = Relaxer(potential=potential_model)\n",
    "    relaxation_results = relaxer.relax(modified_structure, fmax=0.1)\n",
    "    \n",
    "    # ####################################################################\n",
    "    #\n",
    "    #   根 据 官 方 文 档 修 正 在 这 里\n",
    "    #   从轨迹的能量列表 .energies 中获取最后一个值\n",
    "    #\n",
    "    # ####################################################################\n",
    "    final_energy = relaxation_results[\"trajectory\"].energies[-1]\n",
    "    \n",
    "    relaxed_structure = relaxation_results[\"final_structure\"]\n",
    "    print(f\"结构弛豫完成。最终能量: {float(final_energy):.3f} eV\")\n",
    "\n",
    "    # --- 2.3. 使用弛豫后的结构预测最终性质 ---\n",
    "    # (这部分代码已在之前调试正确，保持不变)\n",
    "    print(\"步骤 2.3: 正在对弛豫后的结构预测带隙...\")\n",
    "    converter = Structure2Graph(element_types=element_types, cutoff=5.0)\n",
    "    graph_tuple = converter.get_graph(relaxed_structure)\n",
    "    g = graph_tuple[0]\n",
    "    state_attr = torch.tensor([0]) # 使用 PBE 精度进行预测\n",
    "    \n",
    "    # 修正数据类型和键名...\n",
    "    if 'node_type' in g.ndata and g.ndata['node_type'].dtype != torch.long:\n",
    "        g.ndata['node_type'] = g.ndata['node_type'].to(torch.long)\n",
    "    if 'frac_coords' in g.ndata:\n",
    "        g.ndata['pos'] = g.ndata.pop('frac_coords')\n",
    "    if 'pbc_offset' in g.edata:\n",
    "        g.edata['pbc_offshift'] = g.edata.pop('pbc_offset')\n",
    "    \n",
    "    # 调用核心模型进行预测\n",
    "    final_prediction = property_model(g, state_attr=state_attr)\n",
    "    \n",
    "    return final_prediction.item()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # --- 3.1 获取一个初始结构作为示例 ---\n",
    "    API_KEY = \"bSpFQg1jCJpFG4CARe0NiSUyXKke56OF\" # 已使用您提供的密钥\n",
    "    initial_structure = None\n",
    "    formula= \"LiFePO4F\"  # 目标化学式\n",
    "    with MPRester(api_key=API_KEY) as mpr:\n",
    "        # 以 LiFePO4F (mp-755813) 为例\n",
    "        docs = mpr.materials.search(formula=formula, fields=[\"structure\"])\n",
    "        if docs:\n",
    "            initial_structure = docs[0].structure\n",
    "    parsed_json = {\n",
    "        \"modification_type\": \"substitute\",\n",
    "        \"new_material_formula\": \"LiAlPO4F\", # 我们可以在最后打印时使用\n",
    "        \"details\": {\n",
    "            \"from_element\": \"Fe\",\n",
    "            \"to_element\": \"Al\"\n",
    "        }\n",
    "    }\n",
    "    if initial_structure:\n",
    "        modification_details_for_function = {\n",
    "            \"from\": parsed_json[\"details\"].get(\"from_element\"),\n",
    "            \"to\": parsed_json[\"details\"].get(\"to_element\"),\n",
    "            \"element\": parsed_json[\"details\"].get(\"element\"),\n",
    "            \"coords\": parsed_json[\"details\"].get(\"coords\")\n",
    "        }\n",
    "\n",
    "        # 这就是您在并发任务中需要调用的核心部分\n",
    "        predicted_bandgap = predict_property_for_modified_structure(\n",
    "            initial_structure=initial_structure,\n",
    "            modification_type=parsed_json[\"modification_type\"], # 使用 'modification_type' 键\n",
    "            modification_details=modification_details_for_function, # 使用转换后的details字典\n",
    "            potential_model=pes_model,\n",
    "            property_model=bandgap_model\n",
    "        )\n",
    "        \n",
    "        # 在打印最终结果时，我们可以用上JSON里的 'new_material_formula'\n",
    "        final_formula = parsed_json.get(\"new_material_formula\", \"N/A\")\n",
    "\n",
    "        print(\"\\n==============================================\")\n",
    "        print(f\"最终预测结果：{final_formula} 的带隙约为 {predicted_bandgap:.3f} eV\")\n",
    "        print(\"==============================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a0a20c",
   "metadata": {},
   "source": [
    "### 抽取一批数据，测试MEGNet模型的准确性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcf647cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u01/mengpengyu/miniconda3/envs/d2l/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 步骤 1: 全局配置和模型加载 ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/u01/mengpengyu/miniconda3/envs/d2l/lib/python3.10/site-packages/matgl/utils/io.py:148: UserWarning: Incompatible model version detected! The code will continue to load the model but it is recommended that you provide a path to an updated model, increment your @model_version in model.json if you are confident that the changes are not problematic, or clear your ~/.matgl cache using `python -c \"import matgl; matgl.clear_cache()\"`\n",
      "  _check_ver(cls_, v)  # Check version of any subclasses too.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "带隙 (BandGap) 模型加载成功！\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving SummaryDoc documents: 100%|██████████| 42390/42390 [00:26<00:00, 1575.13it/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from mp_api.client import MPRester\n",
    "import matgl\n",
    "\n",
    "print(\"--- 步骤 1: 全局配置和模型加载 ---\")\n",
    "API_KEY = \"bSpFQg1jCJpFG4CARe0NiSUyXKke56OF\" \n",
    "\n",
    "\n",
    "# 直接加载完整的模型包装器，我们将使用它的高级接口\n",
    "bandgap_model_wrapper = matgl.load_model(\"MEGNet-MP-2019.4.1-BandGap-mfi\")\n",
    "print(\"带隙 (BandGap) 模型加载成功！\")\n",
    "\n",
    "\n",
    "\n",
    "with MPRester(api_key=API_KEY) as mpr:\n",
    "    # --- 3.1 从数据库中进行广泛搜索 ---\n",
    "\n",
    "    \n",
    "    fields_to_request = [\"material_id\", \"formula_pretty\", \"band_gap\"]\n",
    "    \n",
    "    # 使用正确的关键字参数和元组进行范围查询\n",
    "    candidate_docs = mpr.materials.summary.search(\n",
    "        energy_above_hull=(None, 0.05),\n",
    "        band_gap=(0.1, None),\n",
    "        fields=fields_to_request\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee2010e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4588.95it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5203.85it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4457.28it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4438.42it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 1417.47it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4128.25it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 7345.54it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4364.52it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4798.97it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4382.76it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4739.33it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4744.69it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4462.03it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4433.73it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 8422.30it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4975.45it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5592.41it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4928.68it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 10979.85it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 8192.00it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4882.78it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5171.77it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 11683.30it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4957.81it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 10727.12it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4951.95it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 11335.96it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 15307.68it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4650.00it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5121.25it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4946.11it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5295.84it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5289.16it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4843.31it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4934.48it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4934.48it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4917.12it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5096.36it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5329.48it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4963.67it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5184.55it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 9868.95it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5090.17it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4969.55it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5356.71it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 4609.13it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5275.85it/s]\n",
      "Retrieving MaterialsDoc documents: 100%|██████████| 1/1 [00:00<00:00, 5146.39it/s]\n"
     ]
    }
   ],
   "source": [
    "SAMPLE_SIZE = 50\n",
    "random_sample = random.sample(candidate_docs, SAMPLE_SIZE)\n",
    "structure_list=[]\n",
    "for i, entry in enumerate(random_sample):\n",
    "    material_id = entry.material_id\n",
    "\n",
    "    structure_doc = mpr.materials.search(material_ids=[material_id], fields=[\"structure\"])[0]\n",
    "    structure = structure_doc.structure\n",
    "    structure_list.append(structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd194d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_prediction(structure, model_wrapper):\n",
    "    \"\"\"\n",
    "    一个简化的函数，直接使用模型的高级接口 predict_structure 进行预测。\n",
    "    \n",
    "    Args:\n",
    "        structure: pymatgen Structure 对象。\n",
    "        model_wrapper: 加载的完整 matgl 模型（包含转换器）。\n",
    "    \"\"\"\n",
    "    # 对于这个多保真度模型，我们使用 state_attr=0 来预测 PBE 带隙，\n",
    "    # 以便和 Materials Project 数据库中的默认带隙值进行对比。\n",
    "    state_attr = torch.tensor([3])\n",
    "    \n",
    "    # 直接调用高级接口，所有的数据转换和修正都在后台自动完成\n",
    "    prediction_tensor = model_wrapper.predict_structure(\n",
    "        structure=structure,\n",
    "        state_attr=state_attr\n",
    "    )\n",
    "    \n",
    "    return prediction_tensor.item()\n",
    "\n",
    "all_results=[]\n",
    "\n",
    "\n",
    "print(f\"已成功筛选出 {len(random_sample)} 个材料用于测试。\")\n",
    "\n",
    "# --- 3.2 遍历样本，进行预测和对比 ---\n",
    "print(\"\\n--- 步骤 3.2: 开始逐个预测并对比结果 ---\")\n",
    "for i, entry in enumerate(random_sample):\n",
    "    material_id = entry.material_id\n",
    "    formula = entry.formula_pretty\n",
    "    true_band_gap = entry.band_gap\n",
    "\n",
    "    print(f\"\\n({i+1}/{SAMPLE_SIZE}) 正在处理: {formula} ({material_id})\")\n",
    "    print(f\"  数据库真实带隙 (DFT): {true_band_gap:.3f} eV\")\n",
    "\n",
    "    try:\n",
    "        structure = structure_list[i]\n",
    "        \n",
    "        # 调用我们简化的预测函数\n",
    "        predicted_band_gap = get_model_prediction(structure, bandgap_model_wrapper)\n",
    "        print(f\"  模型预测带隙 (ML):   {predicted_band_gap:.3f} eV\")\n",
    "        \n",
    "        # 保存结果\n",
    "        all_results.append({\n",
    "            \"id\": material_id,\n",
    "            \"formula\": formula,\n",
    "            \"true_gap\": true_band_gap,\n",
    "            \"predicted_gap\": predicted_band_gap\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"  处理 {material_id} 时出错: {e}。跳过此样本。\")\n",
    "\n",
    "# --- 3.3 计算并输出最终的准确性指标 ---\n",
    "print(\"\\n--- 步骤 3.3: 计算模型整体准确性 ---\")\n",
    "if all_results:\n",
    "    true_values = np.array([res[\"true_gap\"] for res in all_results])\n",
    "    predicted_values = np.array([res[\"predicted_gap\"] for res in all_results])\n",
    "    \n",
    "    mae = np.mean(np.abs(true_values - predicted_values))\n",
    "    \n",
    "    print(\"\\n================ 最终评估结果 ================\")\n",
    "    print(f\"成功测试了 {len(all_results)} 个样本。\")\n",
    "    print(f\"平均绝对误差 (MAE): {mae:.3f} eV\")\n",
    "    print(\"==============================================\")\n",
    "    print(\"\\n*注: MAE 是“预测值”与“真实值”之间差值的平均数，这个值越小，说明模型预测越准确。\")\n",
    "else:\n",
    "    print(\"没有成功完成的测试样本，无法计算准确性。\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7376153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 步骤2: 正在从本地路径 '/u01/mengpengyu/.cache/alignn/mp_gappbe_alignn' 加载 ALIGNN 模型... ---\n",
      "模型从本地加载成功！\n",
      "\n",
      "--- 步骤3: 正在准备图数据并进行预测... ---\n",
      "\n",
      "加载或预测过程中发生错误:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_1422611/4223934370.py\", line 53, in <module>\n",
      "    g, lg = Graph.atom_dgl_multigraph(atoms)\n",
      "  File \"/u01/mengpengyu/miniconda3/envs/d2l/lib/python3.10/site-packages/alignn/graphs.py\", line 491, in atom_dgl_multigraph\n",
      "    edges, images = nearest_neighbor_edges(\n",
      "  File \"/u01/mengpengyu/miniconda3/envs/d2l/lib/python3.10/site-packages/alignn/graphs.py\", line 164, in nearest_neighbor_edges\n",
      "    all_neighbors = atoms.get_all_neighbors(r=cutoff)\n",
      "AttributeError: 'MSONAtoms' object has no attribute 'get_all_neighbors'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "from mp_api.client import MPRester\n",
    "from alignn.models.alignn import ALIGNN, ALIGNNConfig\n",
    "from alignn.models.alignn_atomwise import ALIGNNAtomWise, ALIGNNAtomWiseConfig # <--- 导入正确的模型类\n",
    "from alignn.graphs import Graph\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "\n",
    "structure= structure_list[0]  # 假设我们使用第一个结构进行预测\n",
    "true_band_gap = random_sample[0].band_gap  # 获取数据库中的真实带隙值\n",
    "model_name_to_use = 'mp_gappbe_alignn' # 这是我们从列表中找到的正确模型名\n",
    "# model_name_to_use = 'jv_mbj_bandgap_alignn'  # 这是我们从列表中找到的正确模型名\n",
    "        # 加载模型的配置文件 (config.json)\n",
    "if structure:\n",
    "    model_name_to_use = 'mp_gappbe_alignn'\n",
    "    MODEL_PATH = os.path.expanduser(f\"~/.cache/alignn/{model_name_to_use}\")\n",
    "\n",
    "    print(f\"\\n--- 步骤2: 正在从本地路径 '{MODEL_PATH}' 加载 ALIGNN 模型... ---\")\n",
    "    \n",
    "    try:\n",
    "        # 加载模型的配置文件 (config.json)\n",
    "        config_path = os.path.join(MODEL_PATH, \"config.json\")\n",
    "        with open(config_path, \"r\") as f:\n",
    "            config_json = json.load(f)\n",
    "\n",
    "        # ####################################################################\n",
    "        #\n",
    "        #   根 据 ValidationEror 的 最 终 修 正\n",
    "        #   在创建配置对象前，手动修正 'name' 字段以满足 ALIGNNAtomWiseConfig 的要求\n",
    "        #\n",
    "        # ####################################################################\n",
    "        config_json['model']['name'] = 'alignn_atomwise'\n",
    "        \n",
    "        # 使用修正后的 'model' 子字典来创建配置对象\n",
    "        config = ALIGNNAtomWiseConfig(**config_json['model'])\n",
    "        \n",
    "        # 使用 ALIGNNAtomWise 来构建模型框架\n",
    "        model = ALIGNNAtomWise(config)\n",
    "        \n",
    "        # 加载预训练好的模型权重 (model.pth)\n",
    "        state = torch.load(os.path.join(MODEL_PATH, \"checkpoint_300.pt\"), map_location=torch.device(\"cpu\"))\n",
    "        model.load_state_dict(state[\"model\"],strict=False)\n",
    "        \n",
    "        print(\"模型从本地加载成功！\")\n",
    "        \n",
    "        # --- 4. 将结构转换为图并进行预测 ---\n",
    "        print(\"\\n--- 步骤3: 正在准备图数据并进行预测... ---\")\n",
    "        \n",
    "        # 将 pymatgen Structure 转换为 ASE Atoms 对象，再转为 dgl 图\n",
    "        atoms = structure.to_ase_atoms()\n",
    "        g, lg = Graph.atom_dgl_multigraph(atoms)\n",
    "        \n",
    "        model.eval() \n",
    "        with torch.no_grad():\n",
    "            # 直接调用模型，传入图对象\n",
    "            prediction = model([g, lg]) \n",
    "            predicted_band_gap = prediction['out'].item()\n",
    "\n",
    "        print(\"\\n--- 预测完成 ---\")\n",
    "        print(f\"ALIGNN 模型预测的带隙为: {predicted_band_gap:.3f} eV\")\n",
    "    \n",
    "        # --- 5. 对比结果 ---\n",
    "        print(\"\\n--- 结果对比 ---\")\n",
    "        error = abs(predicted_band_gap - true_band_gap)\n",
    "        print(f\"模型预测值与数据库真实值的绝对误差为: {error:.3f} eV\")\n",
    "\n",
    "    except Exception as e:\n",
    "        import traceback\n",
    "        print(f\"\\n加载或预测过程中发生错误:\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac4c1d4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like ysuz/Mistral-Nemo-Base-2407-bandgap is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/util/connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/util/connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[0;32m--> 787\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connectionpool.py:488\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    487\u001b[0m         new_e \u001b[38;5;241m=\u001b[39m _wrap_proxy_error(new_e, conn\u001b[38;5;241m.\u001b[39mproxy\u001b[38;5;241m.\u001b[39mscheme)\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[1;32m    490\u001b[0m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connectionpool.py:464\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    463\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 464\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connectionpool.py:1093\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_closed:\n\u001b[0;32m-> 1093\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1095\u001b[0m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connection.py:704\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m sock: socket\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;241m|\u001b[39m ssl\u001b[38;5;241m.\u001b[39mSSLSocket\n\u001b[0;32m--> 704\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m sock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m server_hostname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    217\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPSConnection object at 0x7f8e09631cc0>: Failed to establish a new connection: [Errno 101] Network is unreachable",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/connectionpool.py:841\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    839\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[0;32m--> 841\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    844\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/urllib3/util/retry.py:519\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    518\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[0;32m--> 519\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    521\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ysuz/Mistral-Nemo-Base-2407-bandgap/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f8e09631cc0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:1376\u001b[0m, in \u001b[0;36m_get_metadata_or_catch_error\u001b[0;34m(repo_id, filename, repo_type, revision, endpoint, proxies, etag_timeout, headers, token, local_files_only, relative_filename, storage_folder)\u001b[0m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1376\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m \u001b[43mget_hf_file_metadata\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m http_error:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:1296\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent, headers)\u001b[0m\n\u001b[1;32m   1295\u001b[0m \u001b[38;5;66;03m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1296\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mHEAD\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1298\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1305\u001b[0m hf_raise_for_status(r)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:280\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 280\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_relative_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;66;03m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;66;03m# This is useful in case of a renamed repository.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:303\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[0;32m--> 303\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mget_session\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    304\u001b[0m hf_raise_for_status(response)\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/utils/_http.py:96\u001b[0m, in \u001b[0;36mUniqueRequestIdAdapter.send\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mRequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mConnectionError\u001b[0m: (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /ysuz/Mistral-Nemo-Base-2407-bandgap/resolve/main/config.json (Caused by NewConnectionError('<urllib3.connection.HTTPSConnection object at 0x7f8e09631cc0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))\"), '(Request ID: f0e7c354-cd38-41e4-a24e-eefe98bcb1ea)')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m                   Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/utils/hub.py:342\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    341\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:114\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[38;5;241m=\u001b[39mfn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, has_token\u001b[38;5;241m=\u001b[39mhas_token, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:862\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 862\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[1;32m    864\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    865\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[1;32m    866\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[1;32m    877\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:969\u001b[0m, in \u001b[0;36m_hf_hub_download_to_cache_dir\u001b[0;34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[0m\n\u001b[1;32m    968\u001b[0m     \u001b[38;5;66;03m# Otherwise, raise appropriate error\u001b[39;00m\n\u001b[0;32m--> 969\u001b[0m     \u001b[43m_raise_on_head_call_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_call_error\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;66;03m# From now on, etag, commit_hash, url and size are not None.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/huggingface_hub/file_download.py:1489\u001b[0m, in \u001b[0;36m_raise_on_head_call_error\u001b[0;34m(head_call_error, force_download, local_files_only)\u001b[0m\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1488\u001b[0m     \u001b[38;5;66;03m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[0;32m-> 1489\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1490\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1491\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is on.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mhead_call_error\u001b[39;00m\n",
      "\u001b[0;31mLocalEntryNotFoundError\u001b[0m: An error happened while trying to locate the file on the Hub and we cannot find the requested files in the local cache. Please check your connection and try again or make sure your Internet connection is on.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n\u001b[1;32m      5\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mysuz/Mistral-Nemo-Base-2407-bandgap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 7\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoModelForCausalLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_id,\n\u001b[1;32m      9\u001b[0m                                              device_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m                                              torch_dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat16,\n\u001b[1;32m     11\u001b[0m                                             )\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# example of input context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py:901\u001b[0m, in \u001b[0;36mAutoTokenizer.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    899\u001b[0m         config \u001b[38;5;241m=\u001b[39m AutoConfig\u001b[38;5;241m.\u001b[39mfor_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_dict)\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m         config \u001b[38;5;241m=\u001b[39m \u001b[43mAutoConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    904\u001b[0m config_tokenizer_class \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtokenizer_class\n\u001b[1;32m    905\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(config, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoTokenizer\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config\u001b[38;5;241m.\u001b[39mauto_map:\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/models/auto/configuration_auto.py:1075\u001b[0m, in \u001b[0;36mAutoConfig.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m   1072\u001b[0m trust_remote_code \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust_remote_code\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m   1073\u001b[0m code_revision \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_revision\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1075\u001b[0m config_dict, unused_kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mPretrainedConfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1076\u001b[0m has_remote_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAutoConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto_map\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1077\u001b[0m has_local_code \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m config_dict \u001b[38;5;129;01mand\u001b[39;00m config_dict[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m CONFIG_MAPPING\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/configuration_utils.py:594\u001b[0m, in \u001b[0;36mPretrainedConfig.get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    592\u001b[0m original_kwargs \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(kwargs)\n\u001b[1;32m    593\u001b[0m \u001b[38;5;66;03m# Get config dict associated with the base config file\u001b[39;00m\n\u001b[0;32m--> 594\u001b[0m config_dict, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_config_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {}, kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/configuration_utils.py:653\u001b[0m, in \u001b[0;36mPretrainedConfig._get_config_dict\u001b[0;34m(cls, pretrained_model_name_or_path, **kwargs)\u001b[0m\n\u001b[1;32m    649\u001b[0m configuration_file \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_configuration_file\u001b[39m\u001b[38;5;124m\"\u001b[39m, CONFIG_NAME) \u001b[38;5;28;01mif\u001b[39;00m gguf_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m gguf_file\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    652\u001b[0m     \u001b[38;5;66;03m# Load from local folder or from cache or download from model Hub and cache\u001b[39;00m\n\u001b[0;32m--> 653\u001b[0m     resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfiguration_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_commit_hash\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_config_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, kwargs\n",
      "File \u001b[0;32m~/miniconda3/envs/d2l/lib/python3.10/site-packages/transformers/utils/hub.py:385\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    380\u001b[0m         resolved_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries\n\u001b[1;32m    382\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_connection_errors\n\u001b[1;32m    383\u001b[0m     ):\n\u001b[1;32m    384\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n\u001b[0;32m--> 385\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt connect to \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mHUGGINGFACE_CO_RESOLVE_ENDPOINT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to load this file, couldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find it in the\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    387\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m cached files and it looks like \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not the path to a directory containing a file named\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_filename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCheckout your internet connection or see how to run the library in offline mode at\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    389\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/docs/transformers/installation#offline-mode\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    390\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    391\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EntryNotFoundError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    392\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _raise_exceptions_for_missing_entries:\n",
      "\u001b[0;31mOSError\u001b[0m: We couldn't connect to 'https://huggingface.co' to load this file, couldn't find it in the cached files and it looks like ysuz/Mistral-Nemo-Base-2407-bandgap is not the path to a directory containing a file named config.json.\nCheckout your internet connection or see how to run the library in offline mode at 'https://huggingface.co/docs/transformers/installation#offline-mode'."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "model_id = \"ysuz/Mistral-Nemo-Base-2407-bandgap\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id,\n",
    "                                             device_map=\"auto\",\n",
    "                                             torch_dtype=torch.float16,\n",
    "                                            )\n",
    "\n",
    "# example of input context\n",
    "structure_text = \"\"\"\n",
    "Reduced Formula: BaSrI4\n",
    "abc   :   5.807091   5.807091   8.251028\n",
    "angles:  90.000000  90.000000  90.000000\n",
    "pbc   :       True       True       True\n",
    "space group: ('P4/mmm', 123)\n",
    "Sites (6)\n",
    "  #  SP      a    b         c    magmom\n",
    "  0  Ba    0.5  0.5  0               -0\n",
    "  1  Sr    0    0    0.5             -0\n",
    "  2  I     0    0.5  0.257945         0\n",
    "  3  I     0.5  0    0.257945         0\n",
    "  4  I     0    0.5  0.742055         0\n",
    "  5  I     0.5  0    0.742055         0\n",
    "\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"Instruction: What is the bandgap value of following material?:\\n{structure_text}\\n\\nOutput:\\n\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=256,\n",
    "        do_sample=True,\n",
    "        temperature=0.5,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.05,\n",
    "    )\n",
    "generated_text = tokenizer.decode(tokens[0], skip_special_tokens=True)\n",
    "print(f\"Generated raw text:\\n{generated_text}\\n\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
