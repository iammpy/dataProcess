{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a3e9b805",
   "metadata": {},
   "source": [
    "### 初始化全局变量，导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ba3f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEED_TARGET_COUNT = True\n",
    "TARGET_COUNT = 10300\n",
    "MAX_WORKERS = 150\n",
    "SIGNAL_MODEL_VOTE_NUM = 3\n",
    "output_tag=\"vote\"\n",
    "NEED_RAG =False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ff416",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from model import call_huoshan,call_openai\n",
    "import pandas as pd\n",
    "import json \n",
    "if \"__file__\" in globals():\n",
    "    os.chdir(os.path.dirname(os.path.abspath(__file__)))\n",
    "\n",
    "raw_data_path= os.path.join(\"raw_data\")\n",
    "\n",
    "sciKnowEval_path = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_filling_final_merged.json\")\n",
    "if sciKnowEval_path.endswith(\".jsonl\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= [json.loads(line) for line in f if line.strip()]\n",
    "elif sciKnowEval_path.endswith(\".json\"):\n",
    "    with open(sciKnowEval_path, \"r\") as f:\n",
    "        sciKnowEval_data= json.load(f)\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported file format: {sciKnowEval_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23b6af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_list = []\n",
    "# for item in sciKnowEval_data:\n",
    "#     subtask= item[\"metadata\"][\"details\"][\"subtask\"]\n",
    "#     if subtask == \"Electromagnetism\":\n",
    "#         new_list.append(item)\n",
    "# sciKnowEval_data = new_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84304a1",
   "metadata": {},
   "source": [
    "#### 采集各类问题"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252d8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from collections import defaultdict\n",
    "# sum_dict = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
    "\n",
    "# sample_list=[]\n",
    "# ## 各个subtask采集5个数据\n",
    "# for entry in sciKnowEval_data:\n",
    "#     subtask = entry[\"metadata\"][\"details\"][\"subtask\"]\n",
    "#     domain = entry[\"metadata\"][\"domain\"]\n",
    "#     task= entry[\"metadata\"][\"details\"][\"task\"]\n",
    "#     if sum_dict[domain][task][subtask] < 30:\n",
    "#         sum_dict[domain][task][subtask] += 1\n",
    "#         sample_list.append(entry)\n",
    "# print(f\"Total number of entries after filtering: {len(sample_list)}\")\n",
    "# output_file = os.path.join(raw_data_path, f\"data_sample.json\")\n",
    "# with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "#     json.dump(sample_list, f, ensure_ascii=False, indent=4)\n",
    "    \n",
    "# sciKnowEval_data=sample_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaeb414",
   "metadata": {},
   "source": [
    "#### rag检索维基百科数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c4f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json # 导入 json 模块\n",
    "from pyserini.search.lucene import LuceneSearcher\n",
    "try:\n",
    "    searcher = LuceneSearcher.from_prebuilt_index('wikipedia-dpr')\n",
    "except Exception as e:\n",
    "    print(f\"初始化失败: {e}\")\n",
    "    # 增加一个清理缓存的提示，以防下载的索引损坏\n",
    "    print(\"如果下载或解压出错，可以尝试删除缓存后重试： rm -rf ~/.pyserini/indexes/\")\n",
    "    exit()\n",
    "\n",
    "def get_rag_input(query):\n",
    "\n",
    "    hits = searcher.search(query, k=5)\n",
    "\n",
    "    retrieved_passages = []\n",
    "    for i, hit in enumerate(hits):\n",
    "\n",
    "        raw_json_string = hit.raw\n",
    "        passage_text = None  # 默认为 None\n",
    "\n",
    "        if raw_json_string:\n",
    "            try:\n",
    "                # 解析 JSON 字符串\n",
    "                doc_data = json.loads(raw_json_string)\n",
    "                # 提取 'contents' 字段\n",
    "                passage_text = doc_data.get('contents')\n",
    "            except json.JSONDecodeError:\n",
    "                print(f\"警告：无法解析文档ID {hit.docid} 的JSON数据。\")\n",
    "\n",
    "        # print(f\"\\n--- [结果 {i+1}] ---\")\n",
    "        # print(f\"文档 ID: {hit.docid}\")\n",
    "        # print(f\"BM25 得分: {hit.score:.5f}\")\n",
    "        # print(f\"段落内容:\\n{passage_text}\")\n",
    "        \n",
    "        # 将有效的内容添加到列表中，以便后续使用\n",
    "        if passage_text:\n",
    "            retrieved_passages.append(passage_text)\n",
    "\n",
    "    # ================= 5. RAG 的下一步 (修正后的逻辑) =================\n",
    "    # 使用我们安全收集到的段落构建上下文\n",
    "    retrieved_context = \"\\n\\n\".join(retrieved_passages)\n",
    "\n",
    "    return retrieved_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34ecd91",
   "metadata": {},
   "source": [
    "#### 处理sciKnowEval数据：生成generation，调用verifier，整合成符合要求的最终dict格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c05e0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "import json_repair\n",
    "from collections import Counter\n",
    "Lock = Lock()\n",
    "new_list= []\n",
    "\n",
    "def sciKnowEval_process_row(row):\n",
    "    \n",
    "    # if len(row[\"generations\"]) >=5:\n",
    "    #     return\n",
    "    # task_type = row[\"metadata\"][\"task_type\"]\n",
    "    id= row[\"id\"]\n",
    "    final_answer = row[\"ground_truth\"][\"final_answer\"]\n",
    "\n",
    "    question = row[\"question\"]\n",
    "    domain = row[\"metadata\"][\"domain\"]\n",
    "    task=row[\"metadata\"][\"details\"][\"task\"]\n",
    "    subtask = row[\"metadata\"][\"details\"][\"subtask\"]\n",
    "    ground_truth = row[\"ground_truth\"][\"final_answer\"]\n",
    "    \n",
    "    \n",
    "#     Related data retrieved from the wikipedia-dpr database:\n",
    "# {{{get_rag_input(question)}}}\n",
    "    # generations:list= row[\"generations\"]\n",
    "    # generations = row[\"generations\"] \n",
    "    prompt=f\"\"\"\n",
    "You are a pragmatic Data Quality Verifier. Your task is to evaluate a given ground_truth answer to determine if it is a reliable \"gold standard\" for automated checking.\n",
    "\n",
    "[Input Data Start]\n",
    "Question:\n",
    "{{{question}}}\n",
    "\n",
    "Ground Truth Answer:\n",
    "{{{ground_truth}}}\n",
    "\n",
    "\n",
    "[Input Data End]\n",
    "\n",
    "Evaluation Instructions:\n",
    "\n",
    "Your decision must be one of three options: Accept, Reject, or Indeterminate.\n",
    "\n",
    "Criteria for \"Accept\":\n",
    "\n",
    "The ground_truth provides a factually correct and unambiguous final answer to the question's main objective.\n",
    "Minor omissions in derivation or explanation are acceptable if the core result is accurate.\n",
    "Minor Formatting Flexibility is Allowed: The answer is still \"Acceptable\" even if it has minor formatting deviations from the question's strict instructions, as long as these deviations are made in good faith to represent all the necessary information clearly and accurately. \n",
    "Criteria for \"Reject\":\n",
    "\n",
    "The final answer provided in the ground_truth is factually incorrect.\n",
    "The ground_truth fails to provide a final answer to the question's main objective.\n",
    "The ground_truth itself is vague, an opinion, or a clear \"hallucination\".\n",
    "Criteria for \"Indeterminate\":\n",
    "\n",
    "Choose this option if the ground_truth's correctness cannot be confidently verified without highly specialized, deep domain knowledge or external tools (e.g., running a simulation, performing a live database search, or solving complex scientific problems).\n",
    "This applies when the answer makes a specific, non-trivial claim that seems plausible but is beyond the scope of a general AI's verification capabilities.\n",
    "Output Format:\n",
    "\n",
    "Strictly output your evaluation as a single JSON object. Do not add any other characters outside of the JSON structure.\n",
    "\n",
    "```\n",
    "{{\n",
    "  \"decision\": \"<'Accept', 'Reject', or 'Indeterminate'>\",\n",
    "  \"justification\": \"<A brief, one-sentence explanation for your decision>\"\n",
    "}}\n",
    "```\n",
    "Your Output:\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    with ThreadPoolExecutor(max_workers=2) as executor:\n",
    "\n",
    "        # doubao_future = executor.submit(call_huoshan, prompt, \"doubao\")\n",
    "        # r1_future = executor.submit(call_huoshan, prompt, \"r1\")\n",
    "        \n",
    "        r1_future=[executor.submit(call_huoshan, prompt, \"r1\") for _ in range(SIGNAL_MODEL_VOTE_NUM)]\n",
    "        doubao_future=[executor.submit(call_huoshan, prompt, \"doubao\") for _ in range(SIGNAL_MODEL_VOTE_NUM)]\n",
    "        qwen_future = [executor.submit(call_huoshan, prompt, \"qwen\") for _ in range(SIGNAL_MODEL_VOTE_NUM)]\n",
    "\n",
    "        # _, doubao_ans = doubao_future.result()\n",
    "        # _, r1_ans = r1_future.result()\n",
    "        doubao_ans = [future.result() for future in doubao_future]\n",
    "        r1_ans = [future.result() for future in r1_future]\n",
    "        qwen_ans = [future.result() for future in qwen_future]\n",
    "        doubao_ans = [json_repair.repair_json(ans,return_objects=True) for _,ans in doubao_ans]\n",
    "        r1_ans = [json_repair.repair_json(ans,return_objects=True) for _,ans in r1_ans]\n",
    "        qwen_ans = [json_repair.repair_json(ans, return_objects=True) for _, ans in qwen_ans]\n",
    "        model_ans = doubao_ans + r1_ans + qwen_ans\n",
    "        decisions_list=[]\n",
    "        for ans in model_ans:\n",
    "            try:\n",
    "                decision = ans[\"decision\"]\n",
    "                if decision not in [\"Accept\", \"Reject\", \"Indeterminate\"]:\n",
    "                    continue\n",
    "                decisions_list.append(decision)\n",
    "            except KeyError:\n",
    "                print(f\"KeyError in ans: {ans}\")\n",
    "                continue\n",
    "        counts = Counter(decisions_list)\n",
    "        most_common_decision = max(counts, key=counts.get)\n",
    "\n",
    "    # doubao_ans= json_repair.repair_json(doubao_ans,return_objects=True)\n",
    "    # r1_ans= json_repair.repair_json(r1_ans,return_objects=True)\n",
    "    res_dict={\n",
    "        \"id\": id,\n",
    "        \"domain\": domain,\n",
    "        \"task\": task,\n",
    "        \"subtask\": subtask,\n",
    "        \"question\": question,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"model_ans\": {\n",
    "            \"doubao\": doubao_ans,\n",
    "            \"r1\": r1_ans,\n",
    "            \"qwen\": qwen_ans\n",
    "        },\n",
    "        \"counts\": counts,\n",
    "        \"decision\": most_common_decision\n",
    "    }\n",
    "    new_list.append(res_dict)\n",
    "    \n",
    "    return res_dict\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6205b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:  99%|█████████▉| 10308/10415 [4:14:50<02:38,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "已达到目标数量 10300，中断任务循环。\n",
      "正在关闭线程池，不再等待剩余的慢任务...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "import pdb\n",
    "import tqdm\n",
    "from threading import Lock\n",
    "res_list = []\n",
    "\n",
    "\n",
    "file_lock= Lock()\n",
    "# 将结果写入JSON文件\n",
    "file_tag=\"repair\"\n",
    "output_file = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score.jsonl\")\n",
    "executor = ThreadPoolExecutor(max_workers=MAX_WORKERS)\n",
    "try:\n",
    "\n",
    "    # 2. 在 try 块内部提交和处理任务\n",
    "    counter = 0\n",
    "    futures = {executor.submit(sciKnowEval_process_row, row): index for index, row in enumerate(sciKnowEval_data)}\n",
    "    for future in tqdm.tqdm(as_completed(futures), total=len(futures), desc=\"Processing rows\"):\n",
    "        index = futures[future]\n",
    "        try:\n",
    "            res=future.result()\n",
    "            if res != -1:\n",
    "                counter += 1\n",
    "            #     json_str = json.dumps(res, ensure_ascii=False)\n",
    "            #     with file_lock:\n",
    "            #         try:\n",
    "            #             f.write(json_str + \"\\n\")\n",
    "            #         except Exception as e:\n",
    "            #             print(f\"Error writing to file {output_file}: {e}\")\n",
    "            #             # pdb.set_trace()\n",
    "                \n",
    "            # if counter % 1000 == 0 and counter != 0:\n",
    "            #     # print(f\"Processed {counter} rows.\")\n",
    "            #     with file_lock, list_lock:\n",
    "            #         try:\n",
    "            #             with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "            #                 json.dump(res_list, f, ensure_ascii=False, indent=4)\n",
    "            #         except Exception as e:\n",
    "            #             print(f\"Error writing to file {output_file}: {e}\")\n",
    "            #             # pdb.set_trace()     \n",
    "            \n",
    "            #### 当达到目标时中断循环\n",
    "  \n",
    "            if counter >= TARGET_COUNT and NEED_TARGET_COUNT:\n",
    "                print(f\"已达到目标数量 {TARGET_COUNT}，中断任务循环。\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {index}: {e}\")\n",
    "            traceback.print_exc()\n",
    "\n",
    "finally:\n",
    "    print(\"正在关闭线程池，不再等待剩余的慢任务...\")\n",
    "    executor.shutdown(wait=False, cancel_futures=True) # 这是唯一被调用的shutdown\n",
    "    # try:\n",
    "    #     print(f\"\\n任务已中断或完成，最终获取了 {len(res_list)} 个结果。\")\n",
    "    #     with open(output_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    #         json.dump(res_list, f, ensure_ascii=False, indent=4)\n",
    "    #     print(\"文件保存成功！\")\n",
    "    # except Exception as e:\n",
    "    #     print(f\"Error writing to file {output_file}: {e}\")\n",
    "    #     pdb.set_trace()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66fb1e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_path = os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_{output_tag}.json\")\n",
    "try:\n",
    "    with open(score_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        \n",
    "        json.dump(new_list, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error writing to file {score_path}: {e}\")\n",
    "    pdb.set_trace()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acc2bd9",
   "metadata": {},
   "source": [
    "#### 统计各个subtask正确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1807fbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import json\n",
    "# path=os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_{output_tag}.json\")\n",
    "# with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "#     new_list = json.load(f)\n",
    "\n",
    "# # 统计各个类别的拒绝率\n",
    "# from collections import defaultdict\n",
    "# doubao_reject_count = defaultdict(lambda : defaultdict(lambda: defaultdict(int)))\n",
    "# sum_count = defaultdict(lambda : defaultdict(lambda: defaultdict(int)))\n",
    "# doubao_indeterminate_count = defaultdict(lambda : defaultdict(lambda: defaultdict(int)))\n",
    "# r1_reject_count = defaultdict(lambda : defaultdict(lambda: defaultdict(int)))\n",
    "# r1_indeterminate_count = defaultdict(lambda : defaultdict(lambda: defaultdict(int)))\n",
    "# for entry in new_list:\n",
    "#     domain = entry[\"domain\"]\n",
    "#     task = entry[\"task\"]\n",
    "#     subtask = entry[\"subtask\"]\n",
    "#     doubao_decision = entry[\"doubao_answer\"][\"decision\"]\n",
    "#     r1_decision = entry[\"r1_answer\"][\"decision\"]\n",
    "#     sum_count[domain][task][subtask] += 1\n",
    "#     if doubao_decision == \"Reject\":\n",
    "#         doubao_reject_count[domain][task][subtask] += 1\n",
    "#     elif doubao_decision == \"Indeterminate\":\n",
    "#         doubao_indeterminate_count[domain][task][subtask] += 1\n",
    "#     if r1_decision == \"Reject\":\n",
    "#         r1_reject_count[domain][task][subtask] += 1\n",
    "#     elif r1_decision == \"Indeterminate\":\n",
    "#         r1_indeterminate_count[domain][task][subtask] += 1\n",
    "\n",
    "\n",
    "# # for domain, tasks in reject_count.items():\n",
    "# #     print(f\"Domain: {domain}\")\n",
    "# #     for task, subtasks in tasks.items():\n",
    "# #         print(f\"    Task: {task}\")\n",
    "# #         for subtask, reject in subtasks.items():\n",
    "# #             indeterminate= indeterminate_count[domain][task][subtask]\n",
    "# #             total = sum_count[domain][task][subtask]\n",
    "# #             if total > 0:\n",
    "# #                 reject_rate = reject / total\n",
    "# #                 indeterminate_rate = indeterminate / total\n",
    "                \n",
    "# #                 print(f\"        Subtask: {subtask}, Reject Rate: {reject_rate:.2%} ({reject}/{total})\")\n",
    "# #                 print(f\"        Subtask: {subtask}, Indeterminate Rate: {indeterminate_rate:.2%} ({indeterminate}/{total})\")\n",
    "# #             else:\n",
    "# #                 print(f\"Domain: {domain}, Task: {task}, Subtask: {subtask}, Reject Rate: N/A (No data)\")\n",
    "\n",
    "# for domain, tasks in sum_count.items():\n",
    "#     print(f\"Domain: {domain}\")\n",
    "#     for task, subtasks in tasks.items():\n",
    "#         print(f\"    Task: {task}\")\n",
    "#         for subtask, total in subtasks.items():\n",
    "#             doubao_reject = doubao_reject_count[domain][task][subtask]\n",
    "#             doubao_indeterminate = doubao_indeterminate_count[domain][task][subtask]\n",
    "#             r1_reject = r1_reject_count[domain][task][subtask]\n",
    "#             r1_indeterminate = r1_indeterminate_count[domain][task][subtask]\n",
    "            \n",
    "#             if total > 0:\n",
    "#                 doubao_reject_rate = doubao_reject / total\n",
    "#                 doubao_indeterminate_rate = doubao_indeterminate / total\n",
    "#                 r1_reject_rate = r1_reject / total\n",
    "#                 r1_indeterminate_rate = r1_indeterminate / total\n",
    "                \n",
    "#                 print(f\"        Subtask: {subtask}, Doubao Reject Rate: {doubao_reject_rate:.2%} ({doubao_reject}/{total}), Doubao Indeterminate Rate: {doubao_indeterminate_rate:.2%} ({doubao_indeterminate}/{total})\")\n",
    "#                 print(f\"        Subtask: {subtask}, R1 Reject Rate: {r1_reject_rate:.2%} ({r1_reject}/{total}), R1 Indeterminate Rate: {r1_indeterminate_rate:.2%} ({r1_indeterminate}/{total})\")\n",
    "#             else:\n",
    "#                 print(f\"Domain: {domain}, Task: {task}, Subtask: {subtask}, Reject Rate: N/A (No data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f864467",
   "metadata": {},
   "source": [
    "#### 统计投票的一致性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dc640b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "投票的一致性统计：\n",
      "决策数量: 6, 数量: 893\n",
      "决策数量: 7, 数量: 939\n",
      "决策数量: 8, 数量: 1474\n",
      "决策数量: 5, 数量: 739\n",
      "决策数量: 9, 数量: 5936\n",
      "决策数量: 4, 数量: 281\n",
      "决策数量: 3, 数量: 38\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "path=os.path.join(raw_data_path, f\"SciKnowEval_processed_openended_score_{output_tag}.json\")\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    new_list = json.load(f)\n",
    "\n",
    "# 统计投票的一致性，即最终的决策数量的分布\n",
    "from collections import defaultdict\n",
    "decssion_num_dict=defaultdict(int)\n",
    "for entry in new_list:\n",
    "    decision = entry[\"decision\"]\n",
    "    decision_num= entry[\"counts\"][decision]\n",
    "    decssion_num_dict[decision_num] += 1\n",
    "# 打印投票的一致性统计\n",
    "print(\"投票的一致性统计：\")\n",
    "for decision_num, count in decssion_num_dict.items():\n",
    "    print(f\"决策数量: {decision_num}, 数量: {count}\") \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyserini_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
